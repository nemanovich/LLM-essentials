{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4aba6048c2fd4f288d4cf3d7d5d199e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eda3fda7195747e89d1b1bc7d4184d55",
              "IPY_MODEL_b3bead60245a4cf1892c0471e415d11c",
              "IPY_MODEL_340947757902467fa91112eae8dbe03a"
            ],
            "layout": "IPY_MODEL_238a4868bc0b4bf6b748a810b3b3351d"
          }
        },
        "eda3fda7195747e89d1b1bc7d4184d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18900b32b65448d59faad0dfa5f349b7",
            "placeholder": "​",
            "style": "IPY_MODEL_6ed6ab7a5bd94b8899b06d9dd5402273",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b3bead60245a4cf1892c0471e415d11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cf2f31ad28b4ac3aa180230916c8c8a",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_856046aa538e4e4797e1f4949adafff2",
            "value": 366
          }
        },
        "340947757902467fa91112eae8dbe03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02e51bd98944bceba3d0b3cd0972fbf",
            "placeholder": "​",
            "style": "IPY_MODEL_bc71bbbef9c441e2a7fa395aeb59b1ec",
            "value": " 366/366 [00:00&lt;00:00, 18.6kB/s]"
          }
        },
        "238a4868bc0b4bf6b748a810b3b3351d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18900b32b65448d59faad0dfa5f349b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed6ab7a5bd94b8899b06d9dd5402273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cf2f31ad28b4ac3aa180230916c8c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856046aa538e4e4797e1f4949adafff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e02e51bd98944bceba3d0b3cd0972fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc71bbbef9c441e2a7fa395aeb59b1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dbb370d564d4cf4b51bcfc599bc9068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dab8de777fa422295ac8dfb4cc40e7f",
              "IPY_MODEL_a9fcc91ca1ee461c9a72e3273f6209cd",
              "IPY_MODEL_4364374080a4424492b88ff38fabd55d"
            ],
            "layout": "IPY_MODEL_741b395e80be43ec9cbe234b44cdbe52"
          }
        },
        "8dab8de777fa422295ac8dfb4cc40e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0a3b78773f1499fa922f029cc8f6537",
            "placeholder": "​",
            "style": "IPY_MODEL_53ada7f724084339b9c43964aac376a7",
            "value": "vocab.txt: "
          }
        },
        "a9fcc91ca1ee461c9a72e3273f6209cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb8aa9c310b24c849f4363da1a05adef",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_304c0a34d1254d87939e380c909da027",
            "value": 1
          }
        },
        "4364374080a4424492b88ff38fabd55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a59f55c0a24348baa2dc0bc2fb4d56e8",
            "placeholder": "​",
            "style": "IPY_MODEL_390c9959bf524775a95a84950ea47178",
            "value": " 232k/? [00:00&lt;00:00, 2.88MB/s]"
          }
        },
        "741b395e80be43ec9cbe234b44cdbe52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a3b78773f1499fa922f029cc8f6537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ada7f724084339b9c43964aac376a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb8aa9c310b24c849f4363da1a05adef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "304c0a34d1254d87939e380c909da027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a59f55c0a24348baa2dc0bc2fb4d56e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390c9959bf524775a95a84950ea47178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2cf34159000493a824dc59e971e3a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8ffe72559fe42fe9cf4066ab0218dec",
              "IPY_MODEL_ab9f20868a964861a84bc1e91ed44fad",
              "IPY_MODEL_e8b089cd3e674a55bafc7b831e23ee9c"
            ],
            "layout": "IPY_MODEL_1fc608ad95e44a058303901c42db567a"
          }
        },
        "b8ffe72559fe42fe9cf4066ab0218dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b09a6e06df1b4d87b46ab70ea302ee4e",
            "placeholder": "​",
            "style": "IPY_MODEL_10ed95c5cbeb477d890dc574237b618b",
            "value": "tokenizer.json: "
          }
        },
        "ab9f20868a964861a84bc1e91ed44fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96429bf644e04037a7ae5454afff412f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b75b660731534fa69e550dbf0b2b9457",
            "value": 1
          }
        },
        "e8b089cd3e674a55bafc7b831e23ee9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2617e4cf4cc9407ca9dc2b33b7cd1937",
            "placeholder": "​",
            "style": "IPY_MODEL_0bf62315efba4b94a6cb5855b45011fe",
            "value": " 711k/? [00:00&lt;00:00, 14.6MB/s]"
          }
        },
        "1fc608ad95e44a058303901c42db567a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09a6e06df1b4d87b46ab70ea302ee4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ed95c5cbeb477d890dc574237b618b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96429bf644e04037a7ae5454afff412f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b75b660731534fa69e550dbf0b2b9457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2617e4cf4cc9407ca9dc2b33b7cd1937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf62315efba4b94a6cb5855b45011fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f220809856da43528fc70641d109283c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1801b5ed0f424dbcae529f153970e3cf",
              "IPY_MODEL_031d3a5848654183bcce09f7f39125c2",
              "IPY_MODEL_4cb073ffb90b4c7aaeecee8535e8a354"
            ],
            "layout": "IPY_MODEL_01d11d4a8f54410b88b32210a4f26b38"
          }
        },
        "1801b5ed0f424dbcae529f153970e3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7f247089e80418d956af23a7c7fe138",
            "placeholder": "​",
            "style": "IPY_MODEL_9f0e04ff75c347ecbca53909b6569ad4",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "031d3a5848654183bcce09f7f39125c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55f483d23d84f7dadb8c66326c2ea78",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79431108d58b47f3b577573911a3145c",
            "value": 125
          }
        },
        "4cb073ffb90b4c7aaeecee8535e8a354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_889f07ff70f84a8f879fe9d36629b996",
            "placeholder": "​",
            "style": "IPY_MODEL_c78867a9ffc7465f850da849bdfcd55f",
            "value": " 125/125 [00:00&lt;00:00, 8.60kB/s]"
          }
        },
        "01d11d4a8f54410b88b32210a4f26b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f247089e80418d956af23a7c7fe138": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f0e04ff75c347ecbca53909b6569ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d55f483d23d84f7dadb8c66326c2ea78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79431108d58b47f3b577573911a3145c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "889f07ff70f84a8f879fe9d36629b996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78867a9ffc7465f850da849bdfcd55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fe07f054263412fac57af29aa117fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beb05b6c2e114b30b76c58bcee42653e",
              "IPY_MODEL_15acc52cff72488ea10a9a0f8dc74551",
              "IPY_MODEL_c2efdf9136d44f3d939504bedc52bc62"
            ],
            "layout": "IPY_MODEL_2bf7d30a1d4b4451a51f2e3ac733f25a"
          }
        },
        "beb05b6c2e114b30b76c58bcee42653e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93fec00a713046b99594aa01ef8e7e7c",
            "placeholder": "​",
            "style": "IPY_MODEL_3d2e1d026d5546f6905d1d152848b0cb",
            "value": "config.json: 100%"
          }
        },
        "15acc52cff72488ea10a9a0f8dc74551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e97f37edd3f45218a8a41276e607dc2",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0986d3f4a25d49edae32cf9ce04261ce",
            "value": 743
          }
        },
        "c2efdf9136d44f3d939504bedc52bc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6127ab5503d449fd97d22749dafec1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_217c5db7c2fc4112bfe03004f9e4fd97",
            "value": " 743/743 [00:00&lt;00:00, 57.0kB/s]"
          }
        },
        "2bf7d30a1d4b4451a51f2e3ac733f25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93fec00a713046b99594aa01ef8e7e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d2e1d026d5546f6905d1d152848b0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e97f37edd3f45218a8a41276e607dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0986d3f4a25d49edae32cf9ce04261ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6127ab5503d449fd97d22749dafec1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217c5db7c2fc4112bfe03004f9e4fd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0efdecc796694f3e91960e62582671b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5eb1cdc48fe349daa7f49d0a898fc8bf",
              "IPY_MODEL_ff481fb4b3e14bd58086efa726039667",
              "IPY_MODEL_b230100d903e44c68b1c1fa76fb333ac"
            ],
            "layout": "IPY_MODEL_149e6769de4f47eb836fb54d63948de1"
          }
        },
        "5eb1cdc48fe349daa7f49d0a898fc8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7bd35a30e3f4646a3e7adb2abdb5707",
            "placeholder": "​",
            "style": "IPY_MODEL_3e65a7fdd60545538fbed0627d1e2ba1",
            "value": "model.safetensors: 100%"
          }
        },
        "ff481fb4b3e14bd58086efa726039667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52b7b1ae1c694f24be64b3c2622194db",
            "max": 133466304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02594b002f554dedb6f05a676030d8d2",
            "value": 133466304
          }
        },
        "b230100d903e44c68b1c1fa76fb333ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44e5d7b10fde451d9992de7e0f63253a",
            "placeholder": "​",
            "style": "IPY_MODEL_66a6dc36a5fe45539f5c68fa577db068",
            "value": " 133M/133M [00:01&lt;00:00, 112MB/s]"
          }
        },
        "149e6769de4f47eb836fb54d63948de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7bd35a30e3f4646a3e7adb2abdb5707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e65a7fdd60545538fbed0627d1e2ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52b7b1ae1c694f24be64b3c2622194db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02594b002f554dedb6f05a676030d8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44e5d7b10fde451d9992de7e0f63253a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a6dc36a5fe45539f5c68fa577db068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96cf5d39c46e488d9a1a308a5398d7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23b81be0dfbf4502843fa41ab963579a",
              "IPY_MODEL_532338e7c466494ab690fc7490639dee",
              "IPY_MODEL_3fa0368d00884c12b7683bd9e5b94f85"
            ],
            "layout": "IPY_MODEL_3816af29ce1a4316a085374933f7a164"
          }
        },
        "23b81be0dfbf4502843fa41ab963579a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_674bf94262bd4f8b9a637cb8abdb83f9",
            "placeholder": "​",
            "style": "IPY_MODEL_bbdf5e74e2304f98a4d07bcf7f1e4085",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "532338e7c466494ab690fc7490639dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dfcf26af942444abb2daf2efe2a4da1",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa41836790184bfca47201273aa1b25f",
            "value": 366
          }
        },
        "3fa0368d00884c12b7683bd9e5b94f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ac1a65d458246b3b0d8791fb03092b6",
            "placeholder": "​",
            "style": "IPY_MODEL_a4d1a154ee234b8b9bdb2ce59e785212",
            "value": " 366/366 [00:00&lt;00:00, 6.05kB/s]"
          }
        },
        "3816af29ce1a4316a085374933f7a164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674bf94262bd4f8b9a637cb8abdb83f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbdf5e74e2304f98a4d07bcf7f1e4085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dfcf26af942444abb2daf2efe2a4da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa41836790184bfca47201273aa1b25f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ac1a65d458246b3b0d8791fb03092b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d1a154ee234b8b9bdb2ce59e785212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "087cf31e96d640c6b18b96fdc71d36a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7e624ba2d8549aba304f283a8c344df",
              "IPY_MODEL_872b5b7e51724246b394c538b8e49a11",
              "IPY_MODEL_3dde447998f14618a3a54b3ab6e01196"
            ],
            "layout": "IPY_MODEL_1d4650a1ea0b4593a50575f1fdbcf24e"
          }
        },
        "b7e624ba2d8549aba304f283a8c344df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61912c2df82a470ba6e4ee7a6dd5bfe5",
            "placeholder": "​",
            "style": "IPY_MODEL_68069498f20747bbb15a356d1e3f28c5",
            "value": "vocab.txt: "
          }
        },
        "872b5b7e51724246b394c538b8e49a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12e013f39940447e93c206f183a18c84",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_310a46271a4646da95801b59b4f87e93",
            "value": 1
          }
        },
        "3dde447998f14618a3a54b3ab6e01196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5420bc06ed57458eb43a2bdfd0e1375e",
            "placeholder": "​",
            "style": "IPY_MODEL_9c80065ff8e3482bb493b1586cc8130d",
            "value": " 232k/? [00:00&lt;00:00, 4.14MB/s]"
          }
        },
        "1d4650a1ea0b4593a50575f1fdbcf24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61912c2df82a470ba6e4ee7a6dd5bfe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68069498f20747bbb15a356d1e3f28c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12e013f39940447e93c206f183a18c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "310a46271a4646da95801b59b4f87e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5420bc06ed57458eb43a2bdfd0e1375e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c80065ff8e3482bb493b1586cc8130d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bcdda5f20b244a2a76359469ef99202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b76142d7a6184bd7b5afd0d5f5a14ba7",
              "IPY_MODEL_299069c34fb244088393ecc0a63173ae",
              "IPY_MODEL_2e76a41f37534ed79a0c9125afd083da"
            ],
            "layout": "IPY_MODEL_6f85db83fb014d7b87a0ec8baf1deff1"
          }
        },
        "b76142d7a6184bd7b5afd0d5f5a14ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c50e650718048e1b6aa3636971205ef",
            "placeholder": "​",
            "style": "IPY_MODEL_f97480805f2b49a685705d8ab0d52772",
            "value": "tokenizer.json: "
          }
        },
        "299069c34fb244088393ecc0a63173ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9f688593a524b0fb9f7ac0019c0b03f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbd6ecc66220419ca7ee1420aaa21965",
            "value": 1
          }
        },
        "2e76a41f37534ed79a0c9125afd083da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8a27d27861548149b512532c57f900a",
            "placeholder": "​",
            "style": "IPY_MODEL_b87881910e754ff5b3e86906d0fb7603",
            "value": " 711k/? [00:00&lt;00:00, 8.43MB/s]"
          }
        },
        "6f85db83fb014d7b87a0ec8baf1deff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c50e650718048e1b6aa3636971205ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f97480805f2b49a685705d8ab0d52772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9f688593a524b0fb9f7ac0019c0b03f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fbd6ecc66220419ca7ee1420aaa21965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8a27d27861548149b512532c57f900a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87881910e754ff5b3e86906d0fb7603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73176be9e5e046cdb1a631a83a178dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55f833c6ef914274aa6dc0123d786bfe",
              "IPY_MODEL_c97ee50552d6441eb681267c1f4e959d",
              "IPY_MODEL_e2c3b6e0675e4b48b02b07bd8df65b14"
            ],
            "layout": "IPY_MODEL_b93073467bdf436a91ad0fccc9d4ccb0"
          }
        },
        "55f833c6ef914274aa6dc0123d786bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e40b6b0ea84a49e59de04ff0d5afbc22",
            "placeholder": "​",
            "style": "IPY_MODEL_0e0ab38c9bfe4ab5af786742eecde3ef",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c97ee50552d6441eb681267c1f4e959d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac7e3e1914e94415befb0d6373df3b7b",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd055024711d4422b6ac60091bb0d557",
            "value": 125
          }
        },
        "e2c3b6e0675e4b48b02b07bd8df65b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e9c056e5804faab61ce0c22b359015",
            "placeholder": "​",
            "style": "IPY_MODEL_bcbd7e99e6b9494cbc83fba86d5848d5",
            "value": " 125/125 [00:00&lt;00:00, 4.22kB/s]"
          }
        },
        "b93073467bdf436a91ad0fccc9d4ccb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40b6b0ea84a49e59de04ff0d5afbc22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e0ab38c9bfe4ab5af786742eecde3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac7e3e1914e94415befb0d6373df3b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd055024711d4422b6ac60091bb0d557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82e9c056e5804faab61ce0c22b359015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbd7e99e6b9494cbc83fba86d5848d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15719b54f6c44824b0a20bfe63ef9fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27be8c22fd6041ed94ab30a41b97f5a5",
              "IPY_MODEL_bdbb9582cc7c437e929a7fd65bd51b83",
              "IPY_MODEL_79b328a0f8e94665901eb120d7964d88"
            ],
            "layout": "IPY_MODEL_704673f545714c61a07ef3d1640fe9bb"
          }
        },
        "27be8c22fd6041ed94ab30a41b97f5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fa8c711ad594846963f80fd3c225e70",
            "placeholder": "​",
            "style": "IPY_MODEL_9208c7e470aa4bc0a91c16be5466e4d1",
            "value": "config.json: 100%"
          }
        },
        "bdbb9582cc7c437e929a7fd65bd51b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e277da193a433ebec639eb9586422a",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3fb81158f5e4fdf836f034128846995",
            "value": 743
          }
        },
        "79b328a0f8e94665901eb120d7964d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b73e4f968bf94265988dc60ad0e4519b",
            "placeholder": "​",
            "style": "IPY_MODEL_f1f69500240c466bb9e758b94b92735a",
            "value": " 743/743 [00:00&lt;00:00, 47.8kB/s]"
          }
        },
        "704673f545714c61a07ef3d1640fe9bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa8c711ad594846963f80fd3c225e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9208c7e470aa4bc0a91c16be5466e4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3e277da193a433ebec639eb9586422a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3fb81158f5e4fdf836f034128846995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b73e4f968bf94265988dc60ad0e4519b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f69500240c466bb9e758b94b92735a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb8866ef6cc84eaaa7778a62aa5b626b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fa17cc1cf704894a8d44cf414ce084b",
              "IPY_MODEL_5c7ea4a1b4434ba4996ec401dad702b1",
              "IPY_MODEL_e9a823f50d9d4ae1868ac89bced20a1d"
            ],
            "layout": "IPY_MODEL_f3d9240858bd4d81b7cdea9c2337d304"
          }
        },
        "5fa17cc1cf704894a8d44cf414ce084b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d984ce5a826e42699a32e61f0cc3fb4e",
            "placeholder": "​",
            "style": "IPY_MODEL_3fb005ac83294774938b1873a296a4a6",
            "value": "model.safetensors: 100%"
          }
        },
        "5c7ea4a1b4434ba4996ec401dad702b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f7dc753b313402ca1f3e53d0d1c4c30",
            "max": 133466304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f856f8aad728422c9b8baa06e7879eab",
            "value": 133466304
          }
        },
        "e9a823f50d9d4ae1868ac89bced20a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513adc167e6240da92d587aeba7bef3c",
            "placeholder": "​",
            "style": "IPY_MODEL_aeb5cbb2e42642ba9e23caed0b0e68e9",
            "value": " 133M/133M [00:01&lt;00:00, 173MB/s]"
          }
        },
        "f3d9240858bd4d81b7cdea9c2337d304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d984ce5a826e42699a32e61f0cc3fb4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb005ac83294774938b1873a296a4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f7dc753b313402ca1f3e53d0d1c4c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f856f8aad728422c9b8baa06e7879eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "513adc167e6240da92d587aeba7bef3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb5cbb2e42642ba9e23caed0b0e68e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nemanovich/LLM-essentials/blob/main/advanced_rag_components.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Engineering Essentials by Nebius Academy\n"
      ],
      "metadata": {
        "id": "qQh7ewhdqZFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced RAG components\n",
        "\n",
        "In this notebook, we'll discuss:\n",
        "\n",
        "* Two-stage RAG pipeline that augments retrieval with **reranking**\n",
        "* **Graph databases** which allow to capture connections inside data better than vector stores do\n",
        "* **Hierarchical Navigable Small World** (**HNSW**) which is the nearest neighbour search algorithm powering many of today's vector stores."
      ],
      "metadata": {
        "id": "QIgO73GPq22_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "WqCgRtIRIcN3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"NEBIUS_API_KEY\"] = userdata.get('NEBIUS_API_KEY')"
      ],
      "metadata": {
        "id": "NRpRGdl5IdJZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two-stage retrieval, take 1: Reranking\n",
        "\n",
        "RAG inherited the idea of two-step retrieval from web search and recommendations.\n",
        "\n",
        "The problem with vector search is that, despite everything, distance between embeddings may fail to fully capture semantic similarity. Model-based relevance scorers might potentially perform better. At the same time, vector search boils down to computing scalar products of vectors, which is significantly cheaper than computing `score(query, database_entry`) for all entries of our database.\n",
        "\n",
        "Inspired by these considerations, the following process is often uses:\n",
        "\n",
        "1. Use cheap vector retrieval to get a large set of candidates (larger than we need)\n",
        "2. Score these candidates with a model, which is a more powerful but at the same time more expensive scorer. These models are often known as **rerankers**.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1mrk83CENtZHTzkqEOBI-frCj4lo7sBSR\" width=600 />\n",
        "\n",
        "[Source](https://www.pinecone.io/learn/series/rag/rerankers/)\n",
        "\n",
        "</center>\n",
        "\n",
        "A popular reranker architecture are **cross encoders** - encoder-only transformers that take a concatenation of two sequences as an input and produce a relevance score\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=14SpSRIyyY_xfrxR4XHkIPitWj5zQTDKz\" width=400 />\n",
        "\n",
        "</center>\n",
        "\n",
        "However, recently LLMs are also being used as rerankers."
      ],
      "metadata": {
        "id": "RNFbIV-wFVZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As examples, we'll use two models from [Mixedbread](https://www.mixedbread.com/) which is a service providing RAG tools including a very good reranker model family.\n",
        "\n",
        "The models we'll try are:\n",
        "\n",
        "1. **mxbai-rerank-large-v1** ([its page on Hugging Face](https://huggingface.co/mixedbread-ai/mxbai-rerank-large-v1)), which is a 435M-size cross-encoder model with context length of 512 tokens - small enough for quick experimentation.\n",
        "\n",
        "  See more details in Mixedbread's [blog post](https://www.mixedbread.com/blog/mxbai-rerank-v1).\n",
        "\n",
        "2. **mxbai-rerank-base-v2** ([its page on Hugging Face](https://huggingface.co/mixedbread-ai/mxbai-rerank-base-v2)), which is an LLM fine tuned from **Qwen-2.5-0.5B**.\n",
        "\n",
        "  The **mxbai-rerank-base-v2** model and its larger counterpart **mxbai-rerank-large-v2** are also interesting due to their training methodology. The authors took the 0.5B and 1.5B version of **Qwen-2.5** as a base model and used a three-stage training process which is quite characteristic for Q1 2025:\n",
        "\n",
        "  ![](https://www.mixedbread.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftraining-methodology.be8e6c37.png&w=1920&q=75&dpl=dpl_7psJGN4mGSVvEewvaP5Y3yiVRQmP)\n",
        "\n",
        "  [Source](https://www.mixedbread.com/blog/mxbai-rerank-v2)\n",
        "\n",
        "  See more details in [their blog post](https://www.mixedbread.com/blog/mxbai-rerank-v2).\n",
        "\n",
        "Due to their small size, these models may be used on CPU, though we'd recommend using GPU for **mxbai-rerank-base-v2**."
      ],
      "metadata": {
        "id": "xveKznt0Q340"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying mxbai-rerank-base-v1**\n",
        "\n",
        "For this simple demonstration, we created 7 documents - some of them tell about the effect of the Elixir of Umbral Sight, while others are here to confuse the reranker. All o them might be fetched by vector search."
      ],
      "metadata": {
        "id": "Y937q7FQWuD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "# Load the model\n",
        "reranker_model = CrossEncoder(\"mixedbread-ai/mxbai-rerank-base-v1\")\n",
        "\n",
        "# Example query and documents\n",
        "query = \"What does the Elixir of Umbral Sight do?\"\n",
        "\n",
        "documents = [\n",
        "    \"The Elixir of Umbral Sight grants the drinker flawless vision in all forms of darkness, both magical and mundane, lasting up to one hour. Popular among night-stalkers and shadow scouts.\",\n",
        "    \"Though rare, the Elixir of Umbral Sight can sometimes be found in alchemical markets of the Shrouded Coast, where a single vial may cost up to 300 silver pieces due to demand from adventuring parties.\",\n",
        "    \"The Elixir of Moon's Grace, often confused with Umbral Sight, enhances low-light vision and heightens balance, but does not function in magical darkness.\",\n",
        "    \"An old bard’s tale claims that the Elixir of Umbral Sight reveals not only darkness, but truth — though most scholars dismiss this as poetic exaggeration.\",\n",
        "    \"The Elixir of Umbral Sight is said to grant sight in total darkness, though the exact duration varies. Some claim it fades faster if the user is afraid.\",\n",
        "    \"The Elixir of Wyrm's Breath allows temporary fire-breathing and heat resistance. Its reddish hue and wax-sealed vials are commonly mistaken for Umbral Sight in low lighting.\",\n",
        "    \"Potions brewed from deep mushroom spores often glow faintly, and while they lack any magical effect, they are sometimes used by smugglers for light in underground tunnels.\"\n",
        "]\n",
        "\n",
        "# Rank results\n",
        "results = reranker_model.rank(query, documents, return_documents=True, top_k=4)"
      ],
      "metadata": {
        "id": "iI04uqm2NEBW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP9K_20TWR8K",
        "outputId": "0cc430f0-eaa0-452d-8aeb-3c4be66631e1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'corpus_id': 0,\n",
              "  'score': np.float32(0.98551756),\n",
              "  'text': 'The Elixir of Umbral Sight grants the drinker flawless vision in all forms of darkness, both magical and mundane, lasting up to one hour. Popular among night-stalkers and shadow scouts.'},\n",
              " {'corpus_id': 4,\n",
              "  'score': np.float32(0.971307),\n",
              "  'text': 'The Elixir of Umbral Sight is said to grant sight in total darkness, though the exact duration varies. Some claim it fades faster if the user is afraid.'},\n",
              " {'corpus_id': 3,\n",
              "  'score': np.float32(0.82615745),\n",
              "  'text': 'An old bard’s tale claims that the Elixir of Umbral Sight reveals not only darkness, but truth — though most scholars dismiss this as poetic exaggeration.'},\n",
              " {'corpus_id': 2,\n",
              "  'score': np.float32(0.3823795),\n",
              "  'text': \"The Elixir of Moon's Grace, often confused with Umbral Sight, enhances low-light vision and heightens balance, but does not function in magical darkness.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying mxbai-rerank-base-v2**"
      ],
      "metadata": {
        "id": "Q48m2PD5Wy-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This might require you to restart a session\n",
        "!pip install -q mxbai-rerank"
      ],
      "metadata": {
        "id": "WYSiwHS9NgTh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mxbai_rerank import MxbaiRerankV2\n",
        "\n",
        "reranker_model = MxbaiRerankV2(\"mixedbread-ai/mxbai-rerank-base-v2\")\n",
        "\n",
        "# Example query and documents\n",
        "query = \"What does the Elixir of Umbral Sight do?\"\n",
        "\n",
        "documents = [\n",
        "    \"The Elixir of Umbral Sight grants the drinker flawless vision in all forms of darkness, both magical and mundane, lasting up to one hour. Popular among night-stalkers and shadow scouts.\",\n",
        "    \"Though rare, the Elixir of Umbral Sight can sometimes be found in alchemical markets of the Shrouded Coast, where a single vial may cost up to 300 silver pieces due to demand from adventuring parties.\",\n",
        "    \"The Elixir of Moon's Grace, often confused with Umbral Sight, enhances low-light vision and heightens balance, but does not function in magical darkness.\",\n",
        "    \"An old bard’s tale claims that the Elixir of Umbral Sight reveals not only darkness, but truth — though most scholars dismiss this as poetic exaggeration.\",\n",
        "    \"The Elixir of Umbral Sight is said to grant sight in total darkness, though the exact duration varies. Some claim it fades faster if the user is afraid.\",\n",
        "    \"The Elixir of Wyrm's Breath allows temporary fire-breathing and heat resistance. Its reddish hue and wax-sealed vials are commonly mistaken for Umbral Sight in low lighting.\",\n",
        "    \"Potions brewed from deep mushroom spores often glow faintly, and while they lack any magical effect, they are sometimes used by smugglers for light in underground tunnels.\"\n",
        "]\n",
        "\n",
        "# Lets get the scores\n",
        "results = reranker_model.rank(query, documents, return_documents=True, top_k=4)\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "y0qZvP05Nhmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XQa9rEgOlvn",
        "outputId": "8b25bf6b-4c6c-42ec-9424-99400ac19082"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[RankResult(index=0, score=10.88914680480957, document='The Elixir of Umbral Sight grants the drinker flawless vision in all forms of darkness, both magical and mundane, lasting up to one hour. Popular among night-stalkers and shadow scouts.'),\n",
              " RankResult(index=3, score=10.011770248413086, document='An old bard’s tale claims that the Elixir of Umbral Sight reveals not only darkness, but truth — though most scholars dismiss this as poetic exaggeration.'),\n",
              " RankResult(index=4, score=9.784035682678223, document='The Elixir of Umbral Sight is said to grant sight in total darkness, though the exact duration varies. Some claim it fades faster if the user is afraid.'),\n",
              " RankResult(index=2, score=8.81064510345459, document=\"The Elixir of Moon's Grace, often confused with Umbral Sight, enhances low-light vision and heightens balance, but does not function in magical darkness.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that **v1** and **v2** output scores of different scale.\n",
        "\n",
        "Adding a reranking stage to a RAG pipeline is quite straightforward, and this will be one of your practical tasks in this lesson."
      ],
      "metadata": {
        "id": "JxohJmz-W1jC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph databases\n",
        "\n",
        "Vector store are great to encode abstract semantic similarity, but their accuracy in retrieving facts and connections may be mediocre. So, in some cases it's better to check other database types.\n",
        "\n",
        "**Graph databases** typically store **knowledge graphs** which contain\n",
        "\n",
        "* **nodes** which are intities of interest to you - in the example below these are people, organizations, and documents\n",
        "* **relations** between nodes - in the example below these are \"[*person*] works at [*organization*]\", \"[*person*] is spouse of [*person*]\", and \"[*person*] is mentioned in [*document*]\"\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1m9uIJ4Avbr-mrOoZ-tOl0MHql89_TV-H\" width=500 />\n",
        "\n",
        "</center>\n",
        "\n",
        "There is a number of particular implementations of graph databases. We'll try [**Neo4j**](https://neo4j.com/)."
      ],
      "metadata": {
        "id": "WKgYerm_mcFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting started with Neo4j\n",
        "\n",
        "First of all, you'll need to registed and get a password. To do this, please go to https://neo4j.com/ and press *Get started for free*. After a simple registration procedure, you'll eventually obtain a **.txt** file with credentials that will likely be formatted as\n",
        "\n",
        "```\n",
        "# Wait 60 seconds before connecting using these details, or login to https://console.neo4j.io to validate the Aura Instance is available\n",
        "NEO4J_URI=<your_uri>\n",
        "NEO4J_USERNAME=<your_username>\n",
        "NEO4J_PASSWORD=<your_password>\n",
        "AURA_INSTANCEID=<your_instance_id>\n",
        "AURA_INSTANCENAME=<your_instance_name>\n",
        "```\n",
        "\n",
        "The following code will, parse such a file, save all the credentials as environmental variables, and initialize connection with your database."
      ],
      "metadata": {
        "id": "x1tzQEf0qiN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-neo4j langchain-openai langchain-huggingface langchain-experimental neo4j\n",
        "!pip install -q lancedb pyarrow tiktoken\n",
        "!pip install -qU langchain-text-splitters\n",
        "!pip install -q openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rUSvCKXrv8H",
        "outputId": "eca0af54-af54-4ae2-a628-4b9e3f96e37d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.11.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_neo4j_config(file_path='neo4j_credentials.txt'):\n",
        "    \"\"\"\n",
        "    Parse a Neo4j Aura configuration file and extract connection details.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the configuration file\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing the parsed connection details\n",
        "    \"\"\"\n",
        "    config = {}\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            for line in file:\n",
        "                # Skip comments and empty lines\n",
        "                line = line.strip()\n",
        "                if not line or line.startswith('#'):\n",
        "                    continue\n",
        "\n",
        "                # Parse key-value pairs\n",
        "                if '=' in line:\n",
        "                    key, value = line.split('=', 1)\n",
        "                    config[key] = value\n",
        "\n",
        "        return config\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{file_path}' not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing file: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "config = parse_neo4j_config()\n",
        "\n",
        "import os\n",
        "\n",
        "from langchain_neo4j import Neo4jGraph\n",
        "\n",
        "os.environ[\"NEO4J_URI\"] = config[\"NEO4J_URI\"]\n",
        "os.environ[\"NEO4J_USERNAME\"] = config[\"NEO4J_USERNAME\"]\n",
        "os.environ[\"NEO4J_PASSWORD\"] = config[\"NEO4J_PASSWORD\"]\n",
        "\n",
        "graph = Neo4jGraph(refresh_schema=False)"
      ],
      "metadata": {
        "id": "zp48eyuXrUcz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `graph` is the connection to the Neo4j database.\n",
        "\n",
        "Now, we'll also need our Nebius AI Studio credentials:"
      ],
      "metadata": {
        "id": "LxPTBIVbsMNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"NEBIUS_API_KEY\"] = userdata.get('NEBIUS_API_KEY')"
      ],
      "metadata": {
        "id": "48GjcFB4sp3i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring a simple graph database\n",
        "\n",
        "I asked ChatGPT to generate a short story for us to play with:"
      ],
      "metadata": {
        "id": "QXCOhG1Ps-zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story = \"\"\"Virenthia is one of the Five Eastern Realms, bordered by Caldrien to the west and Eshkar to the south. Since the War of Withering (1023 AE), it has been ruled by the House of Halveric, a noble dynasty claiming descent from the Moonbound Kings of old.\n",
        "\n",
        "The current monarch of Virenthia, Queen Aeryn Halveric, ascended the throne in 1127 AE following the death of her father, King Thandor Halveric, who ruled for nearly three decades.\n",
        "\n",
        "Virenthia maintains tense diplomatic ties with Eshkar, which has long disputed the control over the border town of Dunmire. In contrast, Virenthia is allied with Caldrien, bound by the marriage pact between Aeryn’s cousin Lord Caelum Halveric and Lady Virelle of Caldrien.\n",
        "\n",
        "Queen Aeryn has named Princess Elira Halveric, her younger sister, as heir presumptive of Virenthia, as she remains unmarried and without children.\"\"\""
      ],
      "metadata": {
        "id": "knSKGMdcvPzU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll create a database capturing\n",
        "\n",
        "* Entities of type `PERSON` and `COUNTRY`\n",
        "* Relationships `RULER_OF`, `NEIGHBOUR_OF` (between countries), and `MENTIONED_IN` (a particular sentence).\n",
        "\n",
        "But how to extract these relations? We could probably do it with rules, but that's not fun! Instead, we'll use LLMs! We can even need to bother with prompts: the **Langchain** library has all the infrastructure; we only need to name the relations and hope that the LLM is powerful enough to understand what we need from it. We'll use **Llama-3.1-70B** served by Nebius AI Studio."
      ],
      "metadata": {
        "id": "33q6S6fjvVPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.prompts.chat import ChatPromptTemplate\n",
        "\n",
        "# This defines the LLM:\n",
        "llm = ChatOpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        "    temperature=0,\n",
        "    model_name=\"meta-llama/Meta-Llama-3.1-70B-Instruct\")\n",
        "\n",
        "llm_transformer = LLMGraphTransformer(\n",
        "    llm=llm,\n",
        "    allowed_nodes=[\"Character\", \"Country\"],\n",
        "    allowed_relationships=[\n",
        "        (\"Character\",\"CHARACTER_IS_RULER_OF\",\"Country\"),\n",
        "        (\"Character\",\"IS_HEIR_OF\",\"Character\"),\n",
        "        (\"Country\",\"COUNTRY_IS_NEIGHBOUR_TO\",\"Country\")\n",
        "    ],\n",
        "    node_properties=[\"ruler:reign_start_year\"],\n",
        "    strict_mode=True\n",
        ")"
      ],
      "metadata": {
        "id": "T7HGKpAJwK8r"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the **LLMGraphTransformer** will (hopefully) find all the required relations and properties."
      ],
      "metadata": {
        "id": "38twNCEGzdNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [Document(page_content=sentence) for sentence in story.split(\"\\n\")]\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
        "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents[0].relationships}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "EQjbidASyJky",
        "outputId": "59a74ae4-362b-4b2d-f03d-640561f38b6a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mget_executor_for_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    581\u001b[0m     ) as executor:\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3776\u001b[0m                 ]\n\u001b[0;32m-> 3777\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3778\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3871349141.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgraph_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_graph_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Nodes:{graph_documents[0].nodes}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Relationships:{graph_documents[0].relationships}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_experimental/graph_transformers/llm.py\u001b[0m in \u001b[0;36mconvert_to_graph_documents\u001b[0;34m(self, documents, config)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGraphDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \"\"\"\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     async def aprocess_response(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_experimental/graph_transformers/llm.py\u001b[0m in \u001b[0;36mprocess_response\u001b[0;34m(self, document, config)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m    838\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0mraw_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0mraw_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3047\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3049\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3050\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3051\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3770\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3772\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mget_executor_for_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3773\u001b[0m                 futures = [\n\u001b[1;32m   3774\u001b[0m                     \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_invoke_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mget_executor_for_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \"\"\"\n\u001b[1;32m    578\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     with ContextThreadPoolExecutor(\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_concurrency\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     ) as executor:\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we're ready to populate the actual database, which is accessible through the `graph` endpoint. With the `include_source=True` option toggled, the documents themselves (i.e. the sentences) will also be present in the database with ``"
      ],
      "metadata": {
        "id": "Y_NNhCgv16pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.add_graph_documents(graph_documents, include_source=True)"
      ],
      "metadata": {
        "id": "jbcFRhK0wJp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now explore your database in the Neo4j visual console: https://console-preview.neo4j.io/tools/explore or try some queries in the \"query\" pane. Just keep in mind that 1-2 minutes may pass before the data is updated on the web side.\n",
        "\n",
        "You'll be able to see something like this:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1XEXEQk-qMnxbPCxLfRm0KZYYNw98HBuC\" width=800 />\n",
        "\n",
        "</center>\n",
        "\n",
        "The extraction isn't flawless, but still it's a nice start.\n",
        "\n",
        "Then return here to try some queries by API."
      ],
      "metadata": {
        "id": "8gF3vMrk2MyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.query(\"MATCH (n) RETURN n LIMIT 10\")"
      ],
      "metadata": {
        "id": "XmKJjiOQ2uMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG with a graph database\n",
        "\n",
        "Now that we have a database describing characters, countries, and relationships between them, we can let an LLM use it to answer questions like \"Who rules Virenthia?\"\n",
        "\n",
        "For that, we're rely on the `GraphCypherQAChain` class from the `langchain_neo4j` library.\n",
        "\n",
        "First of all, we'll refresh the schema to be sure that the `graph` endpoint has up-to-date understanding of the node and connection types."
      ],
      "metadata": {
        "id": "JsOgq0OgOukv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.refresh_schema()"
      ],
      "metadata": {
        "id": "1Ue7nA6fOV1W"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's define the `GraphCypherQAChain` that will wrap all the process for us. Under the hood, three stages will be performed:\n",
        "\n",
        "* The LLM will formulate a query to the graph database using the prompts that Langchain and Neo4j provided\n",
        "* The graph database will run the query, (hopefully) fetching some data\n",
        "* The LLM will formulate the final answer"
      ],
      "metadata": {
        "id": "Q_3ANFsBPqys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_neo4j.chains.graph_qa.cypher import GraphCypherQAChain\n",
        "\n",
        "qa_llm = ChatOpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        "    temperature=0,\n",
        "    model_name=\"meta-llama/Meta-Llama-3.1-70B-Instruct\")\n",
        "\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    llm=qa_llm, graph=graph, verbose=True,\n",
        "    allow_dangerous_requests=True # I love this one\n",
        ")"
      ],
      "metadata": {
        "id": "0ybtMbHTK4YI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be useful to check that the `chain` has correct understanding of node and relation types. They should be just as in the graph database:"
      ],
      "metadata": {
        "id": "jqzow9fFQaxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.graph_schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmnquCWZOZxu",
        "outputId": "a3b8c328-ea69-4d90-f2ef-b97eb0d02f10"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node properties:\n",
            "Document {id: STRING, text: STRING}\n",
            "Country {id: STRING}\n",
            "Relationship properties:\n",
            "\n",
            "The relationships:\n",
            "(:Document)-[:MENTIONS]->(:Country)\n",
            "(:Country)-[:COUNTRY_IS_NEIGHBOUR_TO]->(:Country)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"\"\"\n",
        "Who rules Virenthia?\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrmF3IGVNZP6",
        "outputId": "18c9db87-708a-4feb-ff73-805788eccefc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (d:Document)-[:MENTIONS]->(c:Country {id: \"Virenthia\"}) RETURN d.text\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'d.text': 'Virenthia is one of the Five Eastern Realms, bordered by Caldrien to the west and Eshkar to the south. Since the War of Withering (1023 AE), it has been ruled by the House of Halveric, a noble dynasty claiming descent from the Moonbound Kings of old.'}, {'d.text': 'The current monarch of Virenthia, Queen Aeryn Halveric, ascended the throne in 1127 AE following the death of her father, King Thandor Halveric, who ruled for nearly three decades.'}, {'d.text': 'Virenthia maintains tense diplomatic ties with Eshkar, which has long disputed the control over the border town of Dunmire. In contrast, Virenthia is allied with Caldrien, bound by the marriage pact between Aeryn’s cousin Lord Caelum Halveric and Lady Virelle of Caldrien.'}, {'d.text': 'Queen Aeryn has named Princess Elira Halveric, her younger sister, as heir presumptive of Virenthia, as she remains unmarried and without children.'}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '\\nWho rules Virenthia?\\n',\n",
              " 'result': 'Virenthia is ruled by the House of Halveric, a noble dynasty, and the current monarch is Queen Aeryn Halveric.'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that if you choose an inferior LLM, it may fail to cope with creating the right query. In the example below, Llama-3.1-8B confuses the direction of the `CHARACTER_IS_RULER_OF` relation: instead of\n",
        "\n",
        "```\n",
        "(c:Character)-[:CHARACTER_IS_RULER_OF]->(co:Country {id: \"Virenthia\"})\n",
        "```\n",
        "\n",
        "it suggests\n",
        "\n",
        "```\n",
        "(c:Country {id: \"Virenthia\"})-[:CHARACTER_IS_RULER_OF]->(r:Character)\n",
        "```"
      ],
      "metadata": {
        "id": "OPukCc-mRYn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weak_qa_llm = ChatOpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        "    temperature=0,\n",
        "    model_name=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
        "\n",
        "weak_chain = GraphCypherQAChain.from_llm(\n",
        "    llm=weak_qa_llm, graph=graph, verbose=True,\n",
        "    allow_dangerous_requests=True # I love this one\n",
        ")\n",
        "\n",
        "weak_chain.invoke(\"\"\"\n",
        "Who rules Virenthia?\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_WrYo9rRg7d",
        "outputId": "46befa2f-3721-4944-db0a-eeeff63306c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (c:Country {id: \"Virenthia\"})-[:COUNTRY_IS_NEIGHBOUR_TO*1..]->(r:Country) RETURN r\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '\\nWho rules Virenthia?\\n', 'result': \"I don't know the answer.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clearing the traces of our activity from the Neo4j instance\n",
        "\n",
        "Finishing working with the graph database, we'll clear it from out Neo4j instance."
      ],
      "metadata": {
        "id": "gDWmv-z7FM6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.query(\"MATCH (n) DETACH DELETE n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1uJv9PO115r",
        "outputId": "866cd1b6-15b7-4c7c-d6e3-1c61e52370b8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two-stage retrieval, take 2: Combining the power of Vector and Graph Databases\n",
        "\n",
        "Vector and graph databases have their own pros and cons:\n",
        "\n",
        "* **Vector stores** are great at establishing *implicit*, topic-level connections between text fragments. For example, vector search draw parallels between discussions of web search and database retrieval.\n",
        "* **Graph databases** capture *explicit* connections between particular entities. For example, it can encapsulate the fact that LanceDB is a vector store.\n",
        "\n",
        "In this, they complement each other perfectly. Thus, adopting both database types in a RAG system may be very beneficial. The two-stage retrieval we'll discuss here is probably the most popular way of combining them.\n",
        "\n",
        "The idea is the following:\n",
        "\n",
        "* On **Stage 1**, a **vector store** is queried, returning several <font color='blue'>documents</font> (<font color='blue'>Doc1</font>, <font color='blue'>Doc2</font>, and <font color='blue'>Doc 3</font> on the image below)\n",
        "* On **Stage 2**, from each of the stage 1 <font color='blue'>documents</font> we make several hops along the **graph database** edges - starting from `MENTIONS` arrows, we get to\n",
        "\n",
        "  - *entities* mentioned in these docs\n",
        "  - and then to other <font color='lightblue'>documents</font> mentioning these *entities*\n",
        "  - and then to yet other *entities* connected to the initial *entities*.\n",
        "\n",
        "  Like in the example below in two hops we reach <font color='lightblue'>Doc4</font>, <font color='green'>Person1</font>, <font color='green'>Person2</font>, <font color='orange'>Org1</font>, and <font color='orange'>Org2</font>.\n",
        "\n",
        "  With Stage 2, we can significantly expand the retrieval's outreach, bringing both new documents and meaningful connections.\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1G2B12OMz39uPmYVIprqi4f2SPyyP1z9h\" width=600 />\n",
        "\n",
        "</center>\n",
        "\n",
        "Let's code this!"
      ],
      "metadata": {
        "id": "TAOG5dtRFYnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically, we have all the ingredients: both **LanceDB** as a vector store and **Neo4j** as a graph database. A tricky thing will be to ensure that documents have same ids in both LanceDB and Neo4j - so that we cound connect them between stages."
      ],
      "metadata": {
        "id": "NdHpgi-4dde9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll experiment with a slightly larger story.\n",
        "\n",
        "<details>\n",
        "<summary>How we came up with this story</summary>\n",
        "\n",
        "The story isn't entirely fiction. We took info from wiki pages of several rulers of VII century England and Wales - [Penda of Mercia](https://en.wikipedia.org/wiki/Penda_of_Mercia), [Edwin of Nortumbria](https://en.wikipedia.org/wiki/Edwin_of_Northumbria), [Oswald of Northumbria](https://en.wikipedia.org/wiki/Oswald_of_Northumbria), [Eanflæd](https://en.wikipedia.org/wiki/Eanfl%C3%A6d) and several more of their contemporaries. Then we thoroughly renamed the characters and the kingdoms and asked GPT-4.5 to weave everything into a single story. VII century is an exciting period of time, but not very well known, so we hope that LLMs wouldn't see through our disguise.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "2yGTiDSikGKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Nebius-Academy/LLM-Engineering-Essentials/raw/main/topic3/northelm.txt -O northelm.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh9Sbw9uluGD",
        "outputId": "2f9506d3-87d5-4092-9a92-d0f7e8d503c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-24 11:55:43--  https://github.com/Nebius-Academy/LLM-Engineering-Essentials/raw/main/topic3/northelm.txt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Nebius-Academy/LLM-Engineering-Essentials/main/topic3/northelm.txt [following]\n",
            "--2025-08-24 11:55:43--  https://raw.githubusercontent.com/Nebius-Academy/LLM-Engineering-Essentials/main/topic3/northelm.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6670 (6.5K) [text/plain]\n",
            "Saving to: ‘northelm.txt’\n",
            "\n",
            "northelm.txt        100%[===================>]   6.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-08-24 11:55:44 (52.4 MB/s) - ‘northelm.txt’ saved [6670/6670]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"northelm.txt\", \"r\") as f:\n",
        "    story = \"\".join(f.readlines())"
      ],
      "metadata": {
        "id": "62SX8hzEmvFD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For your convenience we'll repeat the installation code here as well as reload the credentials:"
      ],
      "metadata": {
        "id": "fS65rXPJd_gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-neo4j langchain-openai langchain-huggingface langchain-experimental neo4j\n",
        "!pip install -q lancedb pyarrow tiktoken\n",
        "!pip install -qU langchain-text-splitters\n",
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "uFeu1OXMesWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ce12a1-0e3b-4a72-afd4-814ac0f5317c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.11.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "from neo4j import GraphDatabase, basic_auth\n",
        "import lancedb\n",
        "from lancedb.pydantic import LanceModel, Vector\n",
        "from lancedb.embeddings import get_registry\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from langchain_neo4j import Neo4jGraph"
      ],
      "metadata": {
        "id": "o5qqm_2Xm0Sf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting your credentials\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"NEBIUS_API_KEY\"] = userdata.get('NEBIUS_API_KEY')\n",
        "\n",
        "def parse_neo4j_config(file_path='neo4j_credentials.txt'):\n",
        "    \"\"\"\n",
        "    Parse a Neo4j Aura configuration file and extract connection details.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the configuration file\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing the parsed connection details\n",
        "    \"\"\"\n",
        "    config = {}\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            for line in file:\n",
        "                # Skip comments and empty lines\n",
        "                line = line.strip()\n",
        "                if not line or line.startswith('#'):\n",
        "                    continue\n",
        "\n",
        "                # Parse key-value pairs\n",
        "                if '=' in line:\n",
        "                    key, value = line.split('=', 1)\n",
        "                    config[key] = value\n",
        "\n",
        "        return config\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{file_path}' not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing file: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Change the file name if you need\n",
        "config = parse_neo4j_config(file_path='neo4j_credentials.txt')\n",
        "\n",
        "os.environ[\"NEO4J_URI\"] = config[\"NEO4J_URI\"]\n",
        "os.environ[\"NEO4J_USERNAME\"] = config[\"NEO4J_USERNAME\"]\n",
        "os.environ[\"NEO4J_PASSWORD\"] = config[\"NEO4J_PASSWORD\"]"
      ],
      "metadata": {
        "id": "CqOfxDy2evks"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we load our story to LanceDB. Note the `chunk_id` field in the `FantasySchema` - they will mirror document ids in the graph database."
      ],
      "metadata": {
        "id": "J6QbRXBnfF_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /tmp/lancedb\n",
        "db = lancedb.connect(\"/tmp/lancedb\")\n",
        "\n",
        "embed_func = get_registry().get(\"huggingface\").create(name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "\n",
        "class FantasySchema(LanceModel):\n",
        "    '''\n",
        "    This is how we store data in the database.\n",
        "    We need to have a vector here, but apart from this, we may have many other fields\n",
        "    '''\n",
        "    text: str = embed_func.SourceField()\n",
        "    vector: Vector(embed_func.ndims()) = embed_func.VectorField(default=None)\n",
        "    chunk_id: str\n",
        "\n",
        "lance_table = db.create_table(\n",
        "    \"fantasy_world\",\n",
        "    mode='overwrite',\n",
        "    schema=FantasySchema\n",
        ")\n",
        "\n",
        "# Split your documents and assign IDs\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
        "    chunk_size=512,\n",
        "    chunk_overlap=64,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "splitted = []\n",
        "# We have only one story:\n",
        "texts = [story]\n",
        "for text in texts:\n",
        "    docs = text_splitter.create_documents([text])\n",
        "    for doc in docs:\n",
        "        cid = str(uuid.uuid4())\n",
        "        splitted.append({\"text\": doc.page_content, \"chunk_id\": cid})\n",
        "\n",
        "# Ingest into LanceDB\n",
        "lance_table.add(splitted, on_bad_vectors=\"drop\")"
      ],
      "metadata": {
        "id": "Xuz3gdZVm0Vq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "4aba6048c2fd4f288d4cf3d7d5d199e1",
            "eda3fda7195747e89d1b1bc7d4184d55",
            "b3bead60245a4cf1892c0471e415d11c",
            "340947757902467fa91112eae8dbe03a",
            "238a4868bc0b4bf6b748a810b3b3351d",
            "18900b32b65448d59faad0dfa5f349b7",
            "6ed6ab7a5bd94b8899b06d9dd5402273",
            "6cf2f31ad28b4ac3aa180230916c8c8a",
            "856046aa538e4e4797e1f4949adafff2",
            "e02e51bd98944bceba3d0b3cd0972fbf",
            "bc71bbbef9c441e2a7fa395aeb59b1ec",
            "2dbb370d564d4cf4b51bcfc599bc9068",
            "8dab8de777fa422295ac8dfb4cc40e7f",
            "a9fcc91ca1ee461c9a72e3273f6209cd",
            "4364374080a4424492b88ff38fabd55d",
            "741b395e80be43ec9cbe234b44cdbe52",
            "b0a3b78773f1499fa922f029cc8f6537",
            "53ada7f724084339b9c43964aac376a7",
            "cb8aa9c310b24c849f4363da1a05adef",
            "304c0a34d1254d87939e380c909da027",
            "a59f55c0a24348baa2dc0bc2fb4d56e8",
            "390c9959bf524775a95a84950ea47178",
            "d2cf34159000493a824dc59e971e3a47",
            "b8ffe72559fe42fe9cf4066ab0218dec",
            "ab9f20868a964861a84bc1e91ed44fad",
            "e8b089cd3e674a55bafc7b831e23ee9c",
            "1fc608ad95e44a058303901c42db567a",
            "b09a6e06df1b4d87b46ab70ea302ee4e",
            "10ed95c5cbeb477d890dc574237b618b",
            "96429bf644e04037a7ae5454afff412f",
            "b75b660731534fa69e550dbf0b2b9457",
            "2617e4cf4cc9407ca9dc2b33b7cd1937",
            "0bf62315efba4b94a6cb5855b45011fe",
            "f220809856da43528fc70641d109283c",
            "1801b5ed0f424dbcae529f153970e3cf",
            "031d3a5848654183bcce09f7f39125c2",
            "4cb073ffb90b4c7aaeecee8535e8a354",
            "01d11d4a8f54410b88b32210a4f26b38",
            "e7f247089e80418d956af23a7c7fe138",
            "9f0e04ff75c347ecbca53909b6569ad4",
            "d55f483d23d84f7dadb8c66326c2ea78",
            "79431108d58b47f3b577573911a3145c",
            "889f07ff70f84a8f879fe9d36629b996",
            "c78867a9ffc7465f850da849bdfcd55f",
            "5fe07f054263412fac57af29aa117fe8",
            "beb05b6c2e114b30b76c58bcee42653e",
            "15acc52cff72488ea10a9a0f8dc74551",
            "c2efdf9136d44f3d939504bedc52bc62",
            "2bf7d30a1d4b4451a51f2e3ac733f25a",
            "93fec00a713046b99594aa01ef8e7e7c",
            "3d2e1d026d5546f6905d1d152848b0cb",
            "5e97f37edd3f45218a8a41276e607dc2",
            "0986d3f4a25d49edae32cf9ce04261ce",
            "6127ab5503d449fd97d22749dafec1ab",
            "217c5db7c2fc4112bfe03004f9e4fd97",
            "0efdecc796694f3e91960e62582671b2",
            "5eb1cdc48fe349daa7f49d0a898fc8bf",
            "ff481fb4b3e14bd58086efa726039667",
            "b230100d903e44c68b1c1fa76fb333ac",
            "149e6769de4f47eb836fb54d63948de1",
            "a7bd35a30e3f4646a3e7adb2abdb5707",
            "3e65a7fdd60545538fbed0627d1e2ba1",
            "52b7b1ae1c694f24be64b3c2622194db",
            "02594b002f554dedb6f05a676030d8d2",
            "44e5d7b10fde451d9992de7e0f63253a",
            "66a6dc36a5fe45539f5c68fa577db068"
          ]
        },
        "outputId": "a4d3099e-375e-4190-ac6f-0816f0091e42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4aba6048c2fd4f288d4cf3d7d5d199e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dbb370d564d4cf4b51bcfc599bc9068"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2cf34159000493a824dc59e971e3a47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f220809856da43528fc70641d109283c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fe07f054263412fac57af29aa117fe8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0efdecc796694f3e91960e62582671b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AddResult(version=2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's populate the graph database. Here, we'll store chunk ids in the metadata of each document as the `id` field."
      ],
      "metadata": {
        "id": "P48UfeUIfkAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ[\"NEBIUS_API_KEY\"],\n",
        "    model_name=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "llm_transformer = LLMGraphTransformer(\n",
        "    llm=llm,\n",
        "    allowed_nodes=[\"Character\", \"Country\"],\n",
        "    allowed_relationships=[\n",
        "        (\"Character\", \"CHARACTER_IS_RULER_OF\", \"Country\"),\n",
        "        (\"Character\", \"IS_HEIR_OF\", \"Character\"),\n",
        "        (\"Country\", \"COUNTRY_IS_NEIGHBOUR_TO\", \"Country\")\n",
        "    ],\n",
        "    strict_mode=True\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=row[\"text\"],\n",
        "        metadata={\n",
        "            \"id\": row[\"chunk_id\"]    # This are the same ids as in the vector store\n",
        "        }\n",
        "    )\n",
        "    for row in splitted\n",
        "]\n",
        "\n",
        "# This may take some time: the LLM will process each document\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
      ],
      "metadata": {
        "id": "kI9s8XSpm0Yj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting to your Neo4j endpoint\n",
        "graph = Neo4jGraph(refresh_schema=False)\n",
        "\n",
        "# Run this query if you want to get rid of previous databases\n",
        "# that may still persist in your Neoj instance\n",
        "graph.query(\"MATCH (n) DETACH DELETE n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhVznmf1w_y3",
        "outputId": "af1cf051-665a-488c-b8bb-abf0389d5c53"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.add_graph_documents(\n",
        "    graph_documents,\n",
        "    include_source=True,    # uses metadata['id'] for MERGE\n",
        "    baseEntityLabel=True    # adds __Entity__ for performance\n",
        ")"
      ],
      "metadata": {
        "id": "lW_ESy3lm0iN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's double check that our text chunks got the same ids in both LanceDB and Neo4j."
      ],
      "metadata": {
        "id": "jgHngPtBgqjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in documents[:8]:\n",
        "    print(doc.metadata['id'], doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvp8_px7gsML",
        "outputId": "fc6644d4-6729-4032-b4ba-1ac2e86d7616"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76339e7b-fb43-4a41-a527-390b63b42d38 1. The Rise of Aelfric the Uniter\n",
            "a3291595-dee5-4fee-81b7-c02f5938f7ef In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence\n",
            "9cb83371-eeed-4809-a7e8-bee542d1c68f . His conquest culminated in the infamous Battle of Chesterspire, where he defeated a coalition of native lords, effectively diminishing their influence in the northern realms. His rule, however, was cut short by betrayal and bloodshed, paving the way for a period of upheaval. Aelfric’s legacy remained, however, as his descendants would reclaim his dream of a united north.\n",
            "04a1f7a5-19af-488b-a0de-0f325b7a09ae 2. The Exile and Return of Eldren\n",
            "2cc8390b-60d3-495a-a768-3dbb6048ae69 After Aelfric's conquests displaced him from his hereditary seat in Deyrmoor, the young Eldren fled into exile at the hospitable court of King Redwald of Eastmere, a kingdom sharing borders with Kentwythe to the south. Eldren spent years honing his diplomatic and martial skills under Redwald’s patronage. Here, Eldren garnered allies and resources, eventually returning at the head of an army supplied by Eastmere and Kentwythe\n",
            "a17a931f-e783-4807-81f5-025c85b910b4 . With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.\n",
            "f09c86a4-d8ce-4ee1-b76c-b9645cbc2f54 3. Eldren’s Faith and Dominion\n",
            "39579f96-1363-4873-abc9-1cc5524e8020 Eldren’s conversion to the rising faith of the south, strongly influenced by his Kentwythian wife Aethelina and the missionary Bishop Paulian, was a turning point in Northelm’s spiritual and political history. In 627, Eldren publicly embraced the new religion, establishing the great Cathedral of Yorven, the seat of the first Bishopric in the north. His reign became synonymous with stability and prosperity, as he expanded his influence into eastern Merravane and beyond the isles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.query(\"\"\"MATCH (d:Document)\n",
        "RETURN d.id, d.text\n",
        "LIMIT 5\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IYtgLstm0lQ",
        "outputId": "42c6849d-f95f-40de-e71c-59d64edcdae0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'d.id': 'a3291595-dee5-4fee-81b7-c02f5938f7ef',\n",
              "  'd.text': 'In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence'},\n",
              " {'d.id': '9cb83371-eeed-4809-a7e8-bee542d1c68f',\n",
              "  'd.text': '. His conquest culminated in the infamous Battle of Chesterspire, where he defeated a coalition of native lords, effectively diminishing their influence in the northern realms. His rule, however, was cut short by betrayal and bloodshed, paving the way for a period of upheaval. Aelfric’s legacy remained, however, as his descendants would reclaim his dream of a united north.'},\n",
              " {'d.id': '04a1f7a5-19af-488b-a0de-0f325b7a09ae',\n",
              "  'd.text': '2. The Exile and Return of Eldren'},\n",
              " {'d.id': '2cc8390b-60d3-495a-a768-3dbb6048ae69',\n",
              "  'd.text': \"After Aelfric's conquests displaced him from his hereditary seat in Deyrmoor, the young Eldren fled into exile at the hospitable court of King Redwald of Eastmere, a kingdom sharing borders with Kentwythe to the south. Eldren spent years honing his diplomatic and martial skills under Redwald’s patronage. Here, Eldren garnered allies and resources, eventually returning at the head of an army supplied by Eastmere and Kentwythe\"},\n",
              " {'d.id': 'a17a931f-e783-4807-81f5-025c85b910b4',\n",
              "  'd.text': '. With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's create a function performing two-stage retrieval:"
      ],
      "metadata": {
        "id": "pafvmpVrhNNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Any, Dict\n",
        "\n",
        "def two_stage_rag(\n",
        "    query: str,\n",
        "    lance_table=None,\n",
        "    graph=None,\n",
        "    lance_schema=None,\n",
        "    max_results: int = 5, # Max documents fetched by vector search\n",
        "    hop_min: int = 1,\n",
        "    hop_max: int = 2,\n",
        "    limit: int = 8, # For hom many documents to seach for paths in the graph\n",
        "    max_paths: int = 8 # Max number of paths to return for each document\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Perform two-stage retrieval using both vector and graph databases.\n",
        "\n",
        "    Args:\n",
        "        query: The user's query\n",
        "        lance_table: LanceDB table\n",
        "        graph: Neo4j graph instance\n",
        "        max_results: Maximum number of vector results to retrieve\n",
        "        hop_min: Minimum number of hops in graph traversal\n",
        "        hop_max: Maximum number of hops in graph traversal\n",
        "        limit: A confusing parameter actually telling\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing query, vector hits, and graph results\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Stage 1: retrieval in LanceDB\n",
        "        docs = lance_table.search(query).limit(max_results).to_pydantic(lance_schema)\n",
        "        chunk_ids = [d.chunk_id for d in docs]  # extract bridge keys\n",
        "\n",
        "        # Stage 2: retrieval in Neo4j\n",
        "        rows = graph.query(\n",
        "            f\"\"\"\n",
        "MATCH (d:Document) WHERE d.id IN $ids\n",
        "OPTIONAL MATCH path=(d)-[*{hop_min}..{hop_max}]-(e)\n",
        "WITH d, COLLECT(path)[0..$maxPaths] AS limitedPaths\n",
        "RETURN\n",
        "  d.id   AS cid,\n",
        "  d.text AS paragraph,\n",
        "  limitedPaths AS paths\n",
        "LIMIT $limit\n",
        "            \"\"\",\n",
        "            params={\"ids\": chunk_ids, \"limit\": limit, \"maxPaths\": max_paths}\n",
        "        )\n",
        "\n",
        "        # Assembling the final output\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"vector_hits\": docs,\n",
        "            \"graph_results\": rows\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error in two-stage retrieval: {str(e)}\")\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"vector_hits\": [],\n",
        "            \"graph_results\": []\n",
        "        }\n"
      ],
      "metadata": {
        "id": "lgfkGDqAm0oP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = two_stage_rag(\n",
        "    \"Name a heir of a heir of the ruler who unified the kingdoms of Beranhold and Deyrmoor\",\n",
        "    lance_table=lance_table,\n",
        "    graph=graph,\n",
        "    lance_schema=FantasySchema,\n",
        "    max_paths=5)\n",
        "\n",
        "print(\"🔍 Vector Hits:\")\n",
        "for doc in output[\"vector_hits\"]:\n",
        "    print(\"-\", doc.text[:80], \"…\")\n",
        "print(\"\\n🔗 Graph Results:\")\n",
        "for row in output[\"graph_results\"]:\n",
        "    print(f\"Chunk {row['cid']}:\")\n",
        "    for p in row[\"paths\"]:\n",
        "        print(\" \", p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBgnvYMXy7Rv",
        "outputId": "904d7012-b27a-406b-beef-112a69c79b9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Vector Hits:\n",
            "- After Eldren’s demise, Northelm fragmented into its ancestral kingdoms once more …\n",
            "- In 634, Aldric, Eanfrith’s younger brother, returned from exile to challenge the …\n",
            "- In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, …\n",
            "- . With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River …\n",
            "- After Aelfric's conquests displaced him from his hereditary seat in Deyrmoor, th …\n",
            "\n",
            "🔗 Graph Results:\n",
            "Chunk a3291595-dee5-4fee-81b7-c02f5938f7ef:\n",
            "  [{'id': 'a3291595-dee5-4fee-81b7-c02f5938f7ef', 'text': 'In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence'}, 'MENTIONS', {'id': 'Beranhold'}]\n",
            "  [{'id': 'a3291595-dee5-4fee-81b7-c02f5938f7ef', 'text': 'In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': 'a17a931f-e783-4807-81f5-025c85b910b4', 'text': '. With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.'}]\n",
            "  [{'id': 'a3291595-dee5-4fee-81b7-c02f5938f7ef', 'text': 'In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': '24cdb475-58af-4740-934b-d4610a42fb88', 'text': 'After Eldren’s demise, Northelm fragmented into its ancestral kingdoms once more. Osric, Eldren’s nephew, rose as the ruler of Deyrmoor, while Eanfrith, son of Aelfric and nephew to Eldren through his sister’s marriage, claimed Beranhold. Both initially reverted to traditional pagan beliefs, causing religious and political upheaval'}]\n",
            "  [{'id': 'a3291595-dee5-4fee-81b7-c02f5938f7ef', 'text': 'In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': 'fdc9e485-a497-4406-b132-ac9ef4469cf5', 'text': 'In 634, Aldric, Eanfrith’s younger brother, returned from exile to challenge the fractured rule of Osric and Eanfrith. A devout follower of Eldren’s faith, Aldric rallied the disillusioned populace and reclaimed both kingdoms after defeating and killing Cadwyr at the pivotal Battle of Heaven’s Field. Unifying Beranhold and Deyrmoor once more under the renewed name of Northelm, Aldric emerged as a hero and saintly figure'}]\n",
            "  [{'id': 'a3291595-dee5-4fee-81b7-c02f5938f7ef', 'text': 'In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence'}, 'MENTIONS', {'id': 'Beranhold'}, 'COUNTRY_IS_NEIGHBOUR_TO', {'id': 'Deyrmoor'}]\n",
            "Chunk 2cc8390b-60d3-495a-a768-3dbb6048ae69:\n",
            "  [{'id': '2cc8390b-60d3-495a-a768-3dbb6048ae69', 'text': \"After Aelfric's conquests displaced him from his hereditary seat in Deyrmoor, the young Eldren fled into exile at the hospitable court of King Redwald of Eastmere, a kingdom sharing borders with Kentwythe to the south. Eldren spent years honing his diplomatic and martial skills under Redwald’s patronage. Here, Eldren garnered allies and resources, eventually returning at the head of an army supplied by Eastmere and Kentwythe\"}, 'MENTIONS', {'id': 'Deyrmoor'}]\n",
            "  [{'id': '2cc8390b-60d3-495a-a768-3dbb6048ae69', 'text': \"After Aelfric's conquests displaced him from his hereditary seat in Deyrmoor, the young Eldren fled into exile at the hospitable court of King Redwald of Eastmere, a kingdom sharing borders with Kentwythe to the south. Eldren spent years honing his diplomatic and martial skills under Redwald’s patronage. Here, Eldren garnered allies and resources, eventually returning at the head of an army supplied by Eastmere and Kentwythe\"}, 'MENTIONS', {'id': 'Deyrmoor'}, 'MENTIONS', {'id': 'a3291595-dee5-4fee-81b7-c02f5938f7ef', 'text': 'In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence'}]\n",
            "  [{'id': '2cc8390b-60d3-495a-a768-3dbb6048ae69', 'text': \"After Aelfric's conquests displaced him from his hereditary seat in Deyrmoor, the young Eldren fled into exile at the hospitable court of King Redwald of Eastmere, a kingdom sharing borders with Kentwythe to the south. Eldren spent years honing his diplomatic and martial skills under Redwald’s patronage. Here, Eldren garnered allies and resources, eventually returning at the head of an army supplied by Eastmere and Kentwythe\"}, 'MENTIONS', {'id': 'Deyrmoor'}, 'MENTIONS', {'id': 'a17a931f-e783-4807-81f5-025c85b910b4', 'text': '. With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.'}]\n",
            "  [{'id': '2cc8390b-60d3-495a-a768-3dbb6048ae69', 'text': \"After Aelfric's conquests displaced him from his hereditary seat in Deyrmoor, the young Eldren fled into exile at the hospitable court of King Redwald of Eastmere, a kingdom sharing borders with Kentwythe to the south. Eldren spent years honing his diplomatic and martial skills under Redwald’s patronage. Here, Eldren garnered allies and resources, eventually returning at the head of an army supplied by Eastmere and Kentwythe\"}, 'MENTIONS', {'id': 'Deyrmoor'}, 'MENTIONS', {'id': '24cdb475-58af-4740-934b-d4610a42fb88', 'text': 'After Eldren’s demise, Northelm fragmented into its ancestral kingdoms once more. Osric, Eldren’s nephew, rose as the ruler of Deyrmoor, while Eanfrith, son of Aelfric and nephew to Eldren through his sister’s marriage, claimed Beranhold. Both initially reverted to traditional pagan beliefs, causing religious and political upheaval'}]\n",
            "  [{'id': '2cc8390b-60d3-495a-a768-3dbb6048ae69', 'text': \"After Aelfric's conquests displaced him from his hereditary seat in Deyrmoor, the young Eldren fled into exile at the hospitable court of King Redwald of Eastmere, a kingdom sharing borders with Kentwythe to the south. Eldren spent years honing his diplomatic and martial skills under Redwald’s patronage. Here, Eldren garnered allies and resources, eventually returning at the head of an army supplied by Eastmere and Kentwythe\"}, 'MENTIONS', {'id': 'Deyrmoor'}, 'MENTIONS', {'id': 'fdc9e485-a497-4406-b132-ac9ef4469cf5', 'text': 'In 634, Aldric, Eanfrith’s younger brother, returned from exile to challenge the fractured rule of Osric and Eanfrith. A devout follower of Eldren’s faith, Aldric rallied the disillusioned populace and reclaimed both kingdoms after defeating and killing Cadwyr at the pivotal Battle of Heaven’s Field. Unifying Beranhold and Deyrmoor once more under the renewed name of Northelm, Aldric emerged as a hero and saintly figure'}]\n",
            "Chunk a17a931f-e783-4807-81f5-025c85b910b4:\n",
            "  [{'id': 'a17a931f-e783-4807-81f5-025c85b910b4', 'text': '. With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.'}, 'MENTIONS', {'id': 'Beranhold'}]\n",
            "  [{'id': 'a17a931f-e783-4807-81f5-025c85b910b4', 'text': '. With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': 'a3291595-dee5-4fee-81b7-c02f5938f7ef', 'text': 'In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence'}]\n",
            "  [{'id': 'a17a931f-e783-4807-81f5-025c85b910b4', 'text': '. With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': '24cdb475-58af-4740-934b-d4610a42fb88', 'text': 'After Eldren’s demise, Northelm fragmented into its ancestral kingdoms once more. Osric, Eldren’s nephew, rose as the ruler of Deyrmoor, while Eanfrith, son of Aelfric and nephew to Eldren through his sister’s marriage, claimed Beranhold. Both initially reverted to traditional pagan beliefs, causing religious and political upheaval'}]\n",
            "  [{'id': 'a17a931f-e783-4807-81f5-025c85b910b4', 'text': '. With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': 'fdc9e485-a497-4406-b132-ac9ef4469cf5', 'text': 'In 634, Aldric, Eanfrith’s younger brother, returned from exile to challenge the fractured rule of Osric and Eanfrith. A devout follower of Eldren’s faith, Aldric rallied the disillusioned populace and reclaimed both kingdoms after defeating and killing Cadwyr at the pivotal Battle of Heaven’s Field. Unifying Beranhold and Deyrmoor once more under the renewed name of Northelm, Aldric emerged as a hero and saintly figure'}]\n",
            "  [{'id': 'a17a931f-e783-4807-81f5-025c85b910b4', 'text': '. With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.'}, 'MENTIONS', {'id': 'Beranhold'}, 'COUNTRY_IS_NEIGHBOUR_TO', {'id': 'Deyrmoor'}]\n",
            "Chunk 24cdb475-58af-4740-934b-d4610a42fb88:\n",
            "  [{'id': '24cdb475-58af-4740-934b-d4610a42fb88', 'text': 'After Eldren’s demise, Northelm fragmented into its ancestral kingdoms once more. Osric, Eldren’s nephew, rose as the ruler of Deyrmoor, while Eanfrith, son of Aelfric and nephew to Eldren through his sister’s marriage, claimed Beranhold. Both initially reverted to traditional pagan beliefs, causing religious and political upheaval'}, 'MENTIONS', {'id': 'Beranhold'}]\n",
            "  [{'id': '24cdb475-58af-4740-934b-d4610a42fb88', 'text': 'After Eldren’s demise, Northelm fragmented into its ancestral kingdoms once more. Osric, Eldren’s nephew, rose as the ruler of Deyrmoor, while Eanfrith, son of Aelfric and nephew to Eldren through his sister’s marriage, claimed Beranhold. Both initially reverted to traditional pagan beliefs, causing religious and political upheaval'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': 'a3291595-dee5-4fee-81b7-c02f5938f7ef', 'text': 'In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence'}]\n",
            "  [{'id': '24cdb475-58af-4740-934b-d4610a42fb88', 'text': 'After Eldren’s demise, Northelm fragmented into its ancestral kingdoms once more. Osric, Eldren’s nephew, rose as the ruler of Deyrmoor, while Eanfrith, son of Aelfric and nephew to Eldren through his sister’s marriage, claimed Beranhold. Both initially reverted to traditional pagan beliefs, causing religious and political upheaval'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': 'a17a931f-e783-4807-81f5-025c85b910b4', 'text': '. With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.'}]\n",
            "  [{'id': '24cdb475-58af-4740-934b-d4610a42fb88', 'text': 'After Eldren’s demise, Northelm fragmented into its ancestral kingdoms once more. Osric, Eldren’s nephew, rose as the ruler of Deyrmoor, while Eanfrith, son of Aelfric and nephew to Eldren through his sister’s marriage, claimed Beranhold. Both initially reverted to traditional pagan beliefs, causing religious and political upheaval'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': 'fdc9e485-a497-4406-b132-ac9ef4469cf5', 'text': 'In 634, Aldric, Eanfrith’s younger brother, returned from exile to challenge the fractured rule of Osric and Eanfrith. A devout follower of Eldren’s faith, Aldric rallied the disillusioned populace and reclaimed both kingdoms after defeating and killing Cadwyr at the pivotal Battle of Heaven’s Field. Unifying Beranhold and Deyrmoor once more under the renewed name of Northelm, Aldric emerged as a hero and saintly figure'}]\n",
            "  [{'id': '24cdb475-58af-4740-934b-d4610a42fb88', 'text': 'After Eldren’s demise, Northelm fragmented into its ancestral kingdoms once more. Osric, Eldren’s nephew, rose as the ruler of Deyrmoor, while Eanfrith, son of Aelfric and nephew to Eldren through his sister’s marriage, claimed Beranhold. Both initially reverted to traditional pagan beliefs, causing religious and political upheaval'}, 'MENTIONS', {'id': 'Beranhold'}, 'COUNTRY_IS_NEIGHBOUR_TO', {'id': 'Deyrmoor'}]\n",
            "Chunk fdc9e485-a497-4406-b132-ac9ef4469cf5:\n",
            "  [{'id': 'fdc9e485-a497-4406-b132-ac9ef4469cf5', 'text': 'In 634, Aldric, Eanfrith’s younger brother, returned from exile to challenge the fractured rule of Osric and Eanfrith. A devout follower of Eldren’s faith, Aldric rallied the disillusioned populace and reclaimed both kingdoms after defeating and killing Cadwyr at the pivotal Battle of Heaven’s Field. Unifying Beranhold and Deyrmoor once more under the renewed name of Northelm, Aldric emerged as a hero and saintly figure'}, 'MENTIONS', {'id': 'Beranhold'}]\n",
            "  [{'id': 'fdc9e485-a497-4406-b132-ac9ef4469cf5', 'text': 'In 634, Aldric, Eanfrith’s younger brother, returned from exile to challenge the fractured rule of Osric and Eanfrith. A devout follower of Eldren’s faith, Aldric rallied the disillusioned populace and reclaimed both kingdoms after defeating and killing Cadwyr at the pivotal Battle of Heaven’s Field. Unifying Beranhold and Deyrmoor once more under the renewed name of Northelm, Aldric emerged as a hero and saintly figure'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': 'a3291595-dee5-4fee-81b7-c02f5938f7ef', 'text': 'In the waning years of the 6th century, Aelfric, a fierce and ambitious warlord, seized control over the divided kingdoms of Beranhold and Deyrmoor, neighbouring realms whose rivalry had long fragmented the region. Through a series of decisive battles, most notably at the River Idle, he established himself as the first High King of Northelm. Known for his unyielding approach to warfare, Aelfric subdued rebellious nobles and fortified his dominion, marking the beginning of Northelm’s ascension to prominence'}]\n",
            "  [{'id': 'fdc9e485-a497-4406-b132-ac9ef4469cf5', 'text': 'In 634, Aldric, Eanfrith’s younger brother, returned from exile to challenge the fractured rule of Osric and Eanfrith. A devout follower of Eldren’s faith, Aldric rallied the disillusioned populace and reclaimed both kingdoms after defeating and killing Cadwyr at the pivotal Battle of Heaven’s Field. Unifying Beranhold and Deyrmoor once more under the renewed name of Northelm, Aldric emerged as a hero and saintly figure'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': 'a17a931f-e783-4807-81f5-025c85b910b4', 'text': '. With Redwald’s decisive aid, Eldren crushed Aelfric at the Battle of the River Idle in 616, reclaiming his birthright. Consolidating power over both Beranhold and Deyrmoor, he emerged as the pre-eminent ruler of Northelm. Eldren’s diplomatic marriage to Princess Aethelina of Kentwythe marked a critical alliance, securing his position among the powerful southern kingdoms and laying the groundwork for cultural integration and trade.'}]\n",
            "  [{'id': 'fdc9e485-a497-4406-b132-ac9ef4469cf5', 'text': 'In 634, Aldric, Eanfrith’s younger brother, returned from exile to challenge the fractured rule of Osric and Eanfrith. A devout follower of Eldren’s faith, Aldric rallied the disillusioned populace and reclaimed both kingdoms after defeating and killing Cadwyr at the pivotal Battle of Heaven’s Field. Unifying Beranhold and Deyrmoor once more under the renewed name of Northelm, Aldric emerged as a hero and saintly figure'}, 'MENTIONS', {'id': 'Beranhold'}, 'MENTIONS', {'id': '24cdb475-58af-4740-934b-d4610a42fb88', 'text': 'After Eldren’s demise, Northelm fragmented into its ancestral kingdoms once more. Osric, Eldren’s nephew, rose as the ruler of Deyrmoor, while Eanfrith, son of Aelfric and nephew to Eldren through his sister’s marriage, claimed Beranhold. Both initially reverted to traditional pagan beliefs, causing religious and political upheaval'}]\n",
            "  [{'id': 'fdc9e485-a497-4406-b132-ac9ef4469cf5', 'text': 'In 634, Aldric, Eanfrith’s younger brother, returned from exile to challenge the fractured rule of Osric and Eanfrith. A devout follower of Eldren’s faith, Aldric rallied the disillusioned populace and reclaimed both kingdoms after defeating and killing Cadwyr at the pivotal Battle of Heaven’s Field. Unifying Beranhold and Deyrmoor once more under the renewed name of Northelm, Aldric emerged as a hero and saintly figure'}, 'MENTIONS', {'id': 'Beranhold'}, 'COUNTRY_IS_NEIGHBOUR_TO', {'id': 'Deyrmoor'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, the graph outputs contain all the paths from Stage 1 docs that Neo4j was able to traverse. To parse and deduplicate this data, we'll have the function `extract_entity_information`. It returns:\n",
        "\n",
        "* Non-document entities (Person, Country etc)\n",
        "* Relationships\n",
        "* Documents with their ids - the latter is needed for further deduplication with documents from LanceDB\n",
        "\n",
        "This data is further deduplicated and merged with documents from Stage 1 by the `process_two_stage_results` functions. The final context is passed to the familiar `answer_with_rag`.\n",
        "\n",
        "Let's try it!"
      ],
      "metadata": {
        "id": "wIv_ML-UhWF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from typing import List, Dict, Any, Union, Optional\n",
        "import uuid\n",
        "\n",
        "# Client setup\n",
        "nebius_client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")\n",
        "llama_8b_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "llama_70b_model = \"meta-llama/Meta-Llama-3.1-70B-Instruct\"\n",
        "\n",
        "def prettify_string(text, max_line_length=80):\n",
        "    \"\"\"Prints a string with line breaks at spaces to prevent horizontal scrolling.\n",
        "    Args:\n",
        "        text: The string to print.\n",
        "        max_line_length: The maximum length of each line.\n",
        "    \"\"\"\n",
        "    output_lines = []\n",
        "    lines = text.split(\"\\n\")\n",
        "    for line in lines:\n",
        "        current_line = \"\"\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if len(current_line) + len(word) + 1 <= max_line_length:\n",
        "                current_line += word + \" \"\n",
        "            else:\n",
        "                output_lines.append(current_line.strip())\n",
        "                current_line = word + \" \"\n",
        "        output_lines.append(current_line.strip())  # Append the last line\n",
        "    return \"\\n\".join(output_lines)\n",
        "\n",
        "def extract_entity_information(rows):\n",
        "    \"\"\"\n",
        "    Extract structured information about entities and relationships from graph data.\n",
        "    Also extracts document texts with their IDs for future reference.\n",
        "\n",
        "    Args:\n",
        "        rows: List of row results from graph query, each containing paths\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing:\n",
        "        - entity_info: Formatted string of entity information\n",
        "        - entity_data: Dictionary of structured entity data\n",
        "        - relationships: List of relationship tuples\n",
        "        - documents: Dictionary mapping document IDs to their texts\n",
        "    \"\"\"\n",
        "    if not rows:\n",
        "        return {\n",
        "            \"entity_info\": \"No relevant entity information found.\",\n",
        "            \"entity_data\": {},\n",
        "            \"relationships\": [],\n",
        "            \"documents\": {}\n",
        "        }\n",
        "\n",
        "    # Data structures to collect information\n",
        "    entities = {}       # Store entity properties by ID\n",
        "    relationships = []  # Store relationships as (start_id, rel_type, end_id) tuples\n",
        "    documents = {}      # Store document texts by ID\n",
        "\n",
        "    # Process each row and its paths\n",
        "    for row in rows:\n",
        "        # Store document from the current row if present\n",
        "        if row.get('cid') and row.get('paragraph'):\n",
        "            documents[row['cid']] = row['paragraph']\n",
        "\n",
        "        # Skip if no paths to process\n",
        "        if not row.get('paths'):\n",
        "            continue\n",
        "\n",
        "        # Process each path in the row\n",
        "        for path in row['paths']:\n",
        "            if not isinstance(path, list) or len(path) < 3:\n",
        "                continue  # Skip invalid paths\n",
        "\n",
        "            # First, extract all nodes from the path\n",
        "            for i, item in enumerate(path):\n",
        "                # Process only dictionary items with an ID (nodes)\n",
        "                if isinstance(item, dict) and 'id' in item:\n",
        "                    node_id = item['id']\n",
        "\n",
        "                    # Store document nodes separately\n",
        "                    if 'text' in item and item['text']:\n",
        "                        documents[node_id] = item['text']\n",
        "                    else:\n",
        "                        # Store other entity properties\n",
        "                        # Skip if this entity already exists in our collection\n",
        "                        if node_id not in entities:\n",
        "                            # Extract all properties except 'id'\n",
        "                            props = {k: v for k, v in item.items() if k != 'id' and v and v != 'null'}\n",
        "                            entities[node_id] = props\n",
        "\n",
        "            # Now extract relationships\n",
        "            for i in range(len(path)):\n",
        "                # Look for node -> relationship -> node pattern\n",
        "                if (i < len(path) - 2 and\n",
        "                    isinstance(path[i], dict) and 'id' in path[i] and\n",
        "                    isinstance(path[i+1], str) and\n",
        "                    isinstance(path[i+2], dict) and 'id' in path[i+2]):\n",
        "\n",
        "                    start_id = path[i]['id']\n",
        "                    rel_type = path[i+1]\n",
        "                    end_id = path[i+2]['id']\n",
        "\n",
        "                    # Skip 'MENTIONS' relationships with document nodes\n",
        "                    if rel_type == 'MENTIONS' and (start_id in documents or end_id in documents):\n",
        "                        continue\n",
        "\n",
        "                    # Add relationship if it doesn't already exist\n",
        "                    relationship = (start_id, rel_type, end_id)\n",
        "                    if relationship not in relationships:\n",
        "                        relationships.append(relationship)\n",
        "\n",
        "    # Format the output text\n",
        "    result_lines = []\n",
        "\n",
        "    # Format entities\n",
        "    if entities:\n",
        "        result_lines.append(\"Entities:\")\n",
        "        for entity_id, props in sorted(entities.items()):\n",
        "            prop_str = \", \".join([f\"{k}: {v}\" for k, v in props.items()])\n",
        "            if prop_str:\n",
        "                result_lines.append(f\"  {entity_id}: {prop_str}\")\n",
        "            else:\n",
        "                result_lines.append(f\"  {entity_id}\")\n",
        "\n",
        "    # Format relationships\n",
        "    if relationships:\n",
        "        if result_lines:  # Add a separator if we already have content\n",
        "            result_lines.append(\"\")\n",
        "        result_lines.append(\"Relationships:\")\n",
        "        for start, rel, end in sorted(relationships):\n",
        "            result_lines.append(f\"  {start} --[{rel}]--> {end}\")\n",
        "\n",
        "    # Create the final formatted string\n",
        "    entity_info = \"\\n\".join(result_lines) if result_lines else \"No relevant entity information found.\"\n",
        "\n",
        "    return {\n",
        "        \"entity_info\": entity_info,\n",
        "        \"entity_data\": entities,\n",
        "        \"relationships\": relationships,\n",
        "        \"documents\": documents\n",
        "    }\n",
        "\n",
        "# Example modification to process_two_stage_results to use the improved function\n",
        "def process_two_stage_results(results):\n",
        "    \"\"\"\n",
        "    Process the results from two-stage retrieval to create a context for the LLM.\n",
        "\n",
        "    Args:\n",
        "        results: Output from two_stage_rag function\n",
        "\n",
        "    Returns:\n",
        "        Formatted context string\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"No relevant information found.\"\n",
        "\n",
        "        # Process vector hits\n",
        "        vector_paragraphs = [doc.text for doc in results.get(\"vector_hits\", [])]\n",
        "\n",
        "        # Process graph results - using the improved extract_entity_information\n",
        "        extracted_info = extract_entity_information(results.get(\"graph_results\", []))\n",
        "\n",
        "        # Get the document texts\n",
        "        graph_paragraphs = list(extracted_info[\"documents\"].values())\n",
        "\n",
        "        # Remove duplicates with vector results\n",
        "        graph_paragraphs = [p for p in graph_paragraphs if p not in vector_paragraphs]\n",
        "\n",
        "        # Combine all contexts\n",
        "        context_parts = []\n",
        "\n",
        "        all_paragraphs = vector_paragraphs + graph_paragraphs\n",
        "        if all_paragraphs:\n",
        "            context_parts.append(\"Document Paragraphs:\\n\" + \"\\n\\n\".join(all_paragraphs))\n",
        "\n",
        "        if extracted_info[\"entity_info\"] and extracted_info[\"entity_info\"] != \"No relevant entity information found.\":\n",
        "            context_parts.append(\"Graph Information:\\n\" + extracted_info[\"entity_info\"])\n",
        "\n",
        "        return \"\\n\\n\".join(context_parts)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing two-stage results: {str(e)}\")\n",
        "        return \"Error processing retrieval results.\"\n",
        "\n",
        "def answer_with_rag(\n",
        "    prompt: str,\n",
        "    system_prompt: Optional[str] = None,\n",
        "    max_tokens: int = 512,\n",
        "    client: OpenAI = nebius_client,\n",
        "    retrieval_model: str = llama_70b_model,\n",
        "    generation_model: str = llama_8b_model,\n",
        "    lance_table = None,\n",
        "    lance_schema=FantasySchema,\n",
        "    graph = None,\n",
        "    prettify: bool = True,\n",
        "    temperature: float = 0.6,\n",
        "    max_results: int = 5,\n",
        "    hop_min: int = 1,\n",
        "    hop_max: int = 2,\n",
        "    max_paths: int = 10,\n",
        "    verbose: bool = False\n",
        ") -> Union[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Generate an answer using enhanced RAG with two-stage retrieval (vector + graph).\n",
        "\n",
        "    Args:\n",
        "        prompt: User's question or prompt\n",
        "        system_prompt: Instructions for the LLM\n",
        "        max_tokens: Maximum number of tokens in the response\n",
        "        client: OpenAI client instance\n",
        "        retrieval_model: Model used for retrieval (if using LLM-based retrieval)\n",
        "        generation_model: Model used for answer generation\n",
        "        lance_table: LanceDB table for vector search\n",
        "        graph: Neo4j graph instance\n",
        "        prettify: Whether to format the output text\n",
        "        temperature: Temperature for response generation\n",
        "        max_results: Maximum number of vector results to retrieve\n",
        "        hop_min: Minimum number of hops in graph traversal\n",
        "        hop_max: Maximum number of hops in graph traversal\n",
        "        verbose: Whether to return the search results as well\n",
        "\n",
        "    Returns:\n",
        "        Generated response incorporating retrieval results or dict with answer and context\n",
        "    \"\"\"\n",
        "    context = \"No relevant information found.\"\n",
        "\n",
        "    # Perform two-stage retrieval if both databases are available\n",
        "    if lance_table and graph:\n",
        "        try:\n",
        "            retrieval_results = two_stage_rag(\n",
        "                query=prompt,\n",
        "                lance_table=lance_table,\n",
        "                lance_schema=lance_schema,\n",
        "                graph=graph,\n",
        "                max_results=max_results,\n",
        "                hop_min=hop_min,\n",
        "                hop_max=hop_max\n",
        "            )\n",
        "            context = process_two_stage_results(retrieval_results)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during retrieval: {str(e)}\")\n",
        "            context = f\"Retrieval failed. Proceeding with limited context.\"\n",
        "    # Fallback to just vector search if graph is not available\n",
        "    elif lance_table:\n",
        "        try:\n",
        "            search_results = lance_table.search(prompt).limit(max_results).to_pydantic(lance_schema)\n",
        "            context = \"\\n\\n\".join([record.text for record in search_results])\n",
        "        except Exception as e:\n",
        "            print(f\"Error during vector search: {str(e)}\")\n",
        "            context = f\"Vector search failed. Proceeding with limited context.\"\n",
        "\n",
        "    # Construct messages with retrieved context\n",
        "    messages = []\n",
        "    if system_prompt:\n",
        "        messages.append({\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_prompt\n",
        "        })\n",
        "\n",
        "    # Add user prompt with context\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"Answer the following query using the context provided.\n",
        "\n",
        "        <context>\n",
        "        {context}\n",
        "        </context>\n",
        "\n",
        "        <query>{prompt}</query>\n",
        "        \"\"\"\n",
        "    })\n",
        "\n",
        "    # Generate completion\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=generation_model,\n",
        "            messages=messages,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature\n",
        "        )\n",
        "\n",
        "        if prettify:\n",
        "            answer = prettify_string(completion.choices[0].message.content)\n",
        "        else:\n",
        "            answer = completion.choices[0].message.content\n",
        "\n",
        "        if verbose:\n",
        "            return {\n",
        "                \"answer\": answer,\n",
        "                \"context\": context\n",
        "            }\n",
        "        else:\n",
        "            return answer\n",
        "    except Exception as e:\n",
        "        error_message = f\"Error generating answer: {str(e)}\"\n",
        "        print(error_message)\n",
        "\n",
        "        if verbose:\n",
        "            return {\n",
        "                \"answer\": error_message,\n",
        "                \"context\": context\n",
        "            }\n",
        "        else:\n",
        "            return error_message\n"
      ],
      "metadata": {
        "id": "NNYz_ht3y7U7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = answer_with_rag(\"Name a heir of a heir of the ruler who unified the kingdoms of Beranhold and Deyrmoor\",\n",
        "                generation_model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
        "                lance_table=lance_table, graph=graph, verbose=True)\n",
        "result[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xw4s_JyYMdRO",
        "outputId": "86827748-cea1-448e-f40e-1a15ee2ad0de"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Aldric'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Though I'd prefer an explanation, this seems to be accurate. Aldric was a heir of Eanfrith, who was a son of Aelfric, who was indeed the ruler who unified Beranhold and Deyrmoor.\n",
        "\n",
        "At the same time, if we switch off graph retrieval, we'll get an incorrect answer:"
      ],
      "metadata": {
        "id": "z8Tqeqdlz6z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = answer_with_rag(\"Name a heir of a heir of the ruler who unified the kingdoms of Beranhold and Deyrmoor\",\n",
        "                generation_model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
        "                lance_table=lance_table, graph=None, verbose=True)\n",
        "result[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0cSnY3qy9sr0",
        "outputId": "87169a2a-3292-43c1-ea27-85483b2cfd9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Aelfric'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We haven't implemented graph-only search here, but feel free to do it using the code from the previous section."
      ],
      "metadata": {
        "id": "jdQ7cvj91Yy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final notes: getting the correct graph\n",
        "\n",
        "Graph retrieval gives a powerful boost to vector search, helping with brining accurate connections - in which vector search may oftern fail. However, its accuracy shouldn't be taken for granted. LLMs may misinterpret the nature of connections while constructing the graph, and if you look closely you'll see some examples of that in our story-based database.\n",
        "\n",
        "Thus, it's better to use a more powerful LLM at the graph construction phase. Yes, it will increase cost, but a malformed knowledge graph would likely cost you more. Also, if you can parse some connections manually, don't hesitate to do it. And of course, a bit of prompt engineering won't hurt. Let's briefly discuss how to do it.\n",
        "\n",
        "Generally, the `LLMTransformer` is a chain. Its first link has the following prompt template:"
      ],
      "metadata": {
        "id": "QhiYnbP41g0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_transformer.chain.first.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUveWG0X9YP1",
        "outputId": "20f1763a-d480-411c-b421-ff73b0d1ce8b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrificing accuracy. Do not add any information that is not explicitly mentioned in the text.\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'.- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.'), additional_kwargs={}),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template=' Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'), additional_kwargs={})]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, the system prompt is quite long and detailed. You can study it and add some additional considerations about your entities and relationships. Also, few-shot examples won't hurt!\n",
        "\n",
        "That's how it can be done:"
      ],
      "metadata": {
        "id": "28JdPV9J9a_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_prompt = llm_transformer.chain.first.messages[0].prompt.template + \"\"\"\n",
        "<Some additional considerations>\n",
        "<Examples>\n",
        "\"\"\"\n",
        "\n",
        "human_prompt = \"\"\" <Your comments go here>\n",
        "Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", human_prompt)\n",
        "])\n",
        "\n",
        "llm_transformer1 = LLMGraphTransformer(\n",
        "    llm=llm,\n",
        "    allowed_nodes=[\"Character\", \"Country\"],\n",
        "    allowed_relationships=[\n",
        "        (\"Character\",\"CHARACTER_IS_RULER_OF\",\"Country\"),\n",
        "        (\"Character\",\"IS_HEIR_OF\",\"Character\"),\n",
        "        (\"Country\",\"COUNTRY_IS_NEIGHBOUR_TO\",\"Country\")\n",
        "    ],\n",
        "    strict_mode=True,\n",
        "    prompt=prompt_template\n",
        ")"
      ],
      "metadata": {
        "id": "hgvbZBkM8_wi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice: Adding a Reranker\n"
      ],
      "metadata": {
        "id": "ztjX8BwcVD-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this task, you'll need to add the **reranking stage** to the `answer_with_rag` function.\n",
        "\n",
        "Compare the results with and without reranking and with different reranking models. Try to come up with tricky and confusing prompts."
      ],
      "metadata": {
        "id": "3YX7so4cX-SP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lancedb pyarrow tiktoken -q\n",
        "!pip install -qU langchain-text-splitters"
      ],
      "metadata": {
        "id": "2-eylR7ediPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4a3bfa-6024-4e47-cd26-9f5894b19b41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\n",
        "        \"\\n\\n\",\n",
        "        \"\\n\",\n",
        "        \".\",\n",
        "        \" \"\n",
        "    ],\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=128,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")"
      ],
      "metadata": {
        "id": "HSQtLO_cdiPf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List\n",
        "from functools import partial\n",
        "\n",
        "import lancedb\n",
        "from lancedb.pydantic import LanceModel, Vector\n",
        "from lancedb.embeddings import get_registry\n",
        "\n",
        "import openai\n",
        "import pyarrow as pa"
      ],
      "metadata": {
        "id": "Ux-p70dSdiPg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from markdown import markdown\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def markdown_to_text(markdown_string):\n",
        "    \"\"\" Converts a markdown string to plaintext \"\"\"\n",
        "\n",
        "    # md -> html -> text since BeautifulSoup can extract text cleanly\n",
        "    html = markdown(markdown_string)\n",
        "\n",
        "    html = re.sub(r'<!--((.|\\n)*)-->', '', html)\n",
        "    html = re.sub('<code>bash', '<code>', html)\n",
        "\n",
        "    # extract text\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    text = ''.join(soup.findAll(text=True))\n",
        "\n",
        "    text = re.sub('```(py|diff|python)', '', text)\n",
        "    text = re.sub('```\\n', '\\n', text)\n",
        "    text = re.sub('-         .*', '', text)\n",
        "    text = text.replace('...', '')\n",
        "    text = re.sub('\\n(\\n)+', '\\n\\n', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def prepare_files(input_dir=\"transformers/docs/source/en/\", output_dir=\"docs\"):\n",
        "    # Convert string paths to Path objects\n",
        "    input_dir = Path(input_dir)\n",
        "    output_dir = Path(output_dir)\n",
        "\n",
        "    # Check if input directory exists\n",
        "    assert input_dir.is_dir(), \"Input directory doesn't exist\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for root, subdirs, files in tqdm(os.walk(input_dir)):\n",
        "        root_path = Path(root)\n",
        "        for file_name in files:\n",
        "            file_path = root_path / file_name\n",
        "            parent = root_path.stem if root_path.stem != input_dir.stem else \"\"\n",
        "\n",
        "            if file_path.is_file():\n",
        "                with open(file_path, encoding=\"utf-8\") as f:\n",
        "                    md = f.read()\n",
        "                text = markdown_to_text(md)\n",
        "\n",
        "                output_file = output_dir / f\"{parent}_{Path(file_name).stem}.txt\"\n",
        "                with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(text)\n"
      ],
      "metadata": {
        "id": "_i5MUrTsew8H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiVA36IEew8H",
        "outputId": "8ed9021d-6a5b-49e6-9383-0b2bcf0c8b86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 331908, done.\u001b[K\n",
            "remote: Counting objects: 100% (173/173), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 331908 (delta 131), reused 97 (delta 97), pack-reused 331735 (from 2)\u001b[K\n",
            "Receiving objects: 100% (331908/331908), 344.00 MiB | 14.18 MiB/s, done.\n",
            "Resolving deltas: 100% (251954/251954), done.\n",
            "Updating files: 100% (5405/5405), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_files()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823dbddc-28b5-422b-ad90-81cd2d4d9c0c",
        "id": "-U8qSrqtew8I"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]/tmp/ipython-input-1156569626.py:21: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n",
            "  text = ''.join(soup.findAll(text=True))\n",
            "7it [00:08,  1.16s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This line is needed in case you've ran this cell before to clear the db dir\n",
        "!rm -rf /tmp/lancedb\n",
        "\n",
        "db = lancedb.connect(\"/tmp/lancedb\")\n",
        "\n",
        "# We use this model as the encoder: https://huggingface.co/BAAI/bge-small-en-v1.5\n",
        "embed_func = get_registry().get(\"huggingface\").create(name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "\n",
        "class BasicSchema(LanceModel):\n",
        "    '''\n",
        "    This is how we store data in the database.\n",
        "    We need to have a vector here, but apart from this, we may have many other fields\n",
        "    '''\n",
        "    text: str = embed_func.SourceField()\n",
        "    vector: Vector(embed_func.ndims()) = embed_func.VectorField(default=None)\n",
        "\n",
        "lance_table = db.create_table(\n",
        "    \"transformer_docs\",\n",
        "    mode='overwrite',\n",
        "    schema=BasicSchema\n",
        ")\n",
        "\n",
        "# Populating the database\n",
        "\n",
        "from tqdm import tqdm\n",
        "splitted_docs = []\n",
        "\n",
        "for file in tqdm(os.listdir(\"docs\")):\n",
        "    with open(\"docs/\"+file, \"r\") as f:\n",
        "        text = f.read()\n",
        "        docs = text_splitter.create_documents([text])\n",
        "        splitted_docs.extend([{\"text\": doc.page_content} for doc in docs])\n",
        "\n",
        "lance_table.add(\n",
        "    splitted_docs,\n",
        "    on_bad_vectors='drop'  # or 'fill' with fill_value=0.0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372,
          "referenced_widgets": [
            "96cf5d39c46e488d9a1a308a5398d7fe",
            "23b81be0dfbf4502843fa41ab963579a",
            "532338e7c466494ab690fc7490639dee",
            "3fa0368d00884c12b7683bd9e5b94f85",
            "3816af29ce1a4316a085374933f7a164",
            "674bf94262bd4f8b9a637cb8abdb83f9",
            "bbdf5e74e2304f98a4d07bcf7f1e4085",
            "3dfcf26af942444abb2daf2efe2a4da1",
            "aa41836790184bfca47201273aa1b25f",
            "2ac1a65d458246b3b0d8791fb03092b6",
            "a4d1a154ee234b8b9bdb2ce59e785212",
            "087cf31e96d640c6b18b96fdc71d36a4",
            "b7e624ba2d8549aba304f283a8c344df",
            "872b5b7e51724246b394c538b8e49a11",
            "3dde447998f14618a3a54b3ab6e01196",
            "1d4650a1ea0b4593a50575f1fdbcf24e",
            "61912c2df82a470ba6e4ee7a6dd5bfe5",
            "68069498f20747bbb15a356d1e3f28c5",
            "12e013f39940447e93c206f183a18c84",
            "310a46271a4646da95801b59b4f87e93",
            "5420bc06ed57458eb43a2bdfd0e1375e",
            "9c80065ff8e3482bb493b1586cc8130d",
            "2bcdda5f20b244a2a76359469ef99202",
            "b76142d7a6184bd7b5afd0d5f5a14ba7",
            "299069c34fb244088393ecc0a63173ae",
            "2e76a41f37534ed79a0c9125afd083da",
            "6f85db83fb014d7b87a0ec8baf1deff1",
            "0c50e650718048e1b6aa3636971205ef",
            "f97480805f2b49a685705d8ab0d52772",
            "d9f688593a524b0fb9f7ac0019c0b03f",
            "fbd6ecc66220419ca7ee1420aaa21965",
            "b8a27d27861548149b512532c57f900a",
            "b87881910e754ff5b3e86906d0fb7603",
            "73176be9e5e046cdb1a631a83a178dec",
            "55f833c6ef914274aa6dc0123d786bfe",
            "c97ee50552d6441eb681267c1f4e959d",
            "e2c3b6e0675e4b48b02b07bd8df65b14",
            "b93073467bdf436a91ad0fccc9d4ccb0",
            "e40b6b0ea84a49e59de04ff0d5afbc22",
            "0e0ab38c9bfe4ab5af786742eecde3ef",
            "ac7e3e1914e94415befb0d6373df3b7b",
            "cd055024711d4422b6ac60091bb0d557",
            "82e9c056e5804faab61ce0c22b359015",
            "bcbd7e99e6b9494cbc83fba86d5848d5",
            "15719b54f6c44824b0a20bfe63ef9fe5",
            "27be8c22fd6041ed94ab30a41b97f5a5",
            "bdbb9582cc7c437e929a7fd65bd51b83",
            "79b328a0f8e94665901eb120d7964d88",
            "704673f545714c61a07ef3d1640fe9bb",
            "0fa8c711ad594846963f80fd3c225e70",
            "9208c7e470aa4bc0a91c16be5466e4d1",
            "a3e277da193a433ebec639eb9586422a",
            "c3fb81158f5e4fdf836f034128846995",
            "b73e4f968bf94265988dc60ad0e4519b",
            "f1f69500240c466bb9e758b94b92735a",
            "fb8866ef6cc84eaaa7778a62aa5b626b",
            "5fa17cc1cf704894a8d44cf414ce084b",
            "5c7ea4a1b4434ba4996ec401dad702b1",
            "e9a823f50d9d4ae1868ac89bced20a1d",
            "f3d9240858bd4d81b7cdea9c2337d304",
            "d984ce5a826e42699a32e61f0cc3fb4e",
            "3fb005ac83294774938b1873a296a4a6",
            "8f7dc753b313402ca1f3e53d0d1c4c30",
            "f856f8aad728422c9b8baa06e7879eab",
            "513adc167e6240da92d587aeba7bef3c",
            "aeb5cbb2e42642ba9e23caed0b0e68e9"
          ]
        },
        "id": "02GseFXJdnBR",
        "outputId": "400e2901-f047-4336-9f7c-36adf4f913ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96cf5d39c46e488d9a1a308a5398d7fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "087cf31e96d640c6b18b96fdc71d36a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bcdda5f20b244a2a76359469ef99202"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73176be9e5e046cdb1a631a83a178dec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15719b54f6c44824b0a20bfe63ef9fe5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb8866ef6cc84eaaa7778a62aa5b626b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 572/572 [00:00<00:00, 5052.45it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AddResult(version=2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "Here is the function you need to modify:"
      ],
      "metadata": {
        "id": "vh61n5GOAJP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from math import e\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "nebius_client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")\n",
        "llama_8b_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "reranker_model = CrossEncoder(\"mixedbread-ai/mxbai-rerank-base-v1\")\n",
        "\n",
        "def prettify_string(text, max_line_length=80):\n",
        "    \"\"\"Prints a string with line breaks at spaces to prevent horizontal scrolling.\n",
        "    Args:\n",
        "        text: The string to print.\n",
        "        max_line_length: The maximum length of each line.\n",
        "    \"\"\"\n",
        "    output_lines = []\n",
        "    lines = text.split(\"\\n\")\n",
        "    for line in lines:\n",
        "        current_line = \"\"\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if len(current_line) + len(word) + 1 <= max_line_length:\n",
        "                current_line += word + \" \"\n",
        "            else:\n",
        "                output_lines.append(current_line.strip())\n",
        "                current_line = word + \" \"\n",
        "        output_lines.append(current_line.strip())  # Append the last line\n",
        "    return \"\\n\".join(output_lines)\n",
        "\n",
        "def search_table(table, query, max_results=15):\n",
        "    return table.search(query).limit(max_results).to_pydantic(BasicSchema)\n",
        "\n",
        "def search_result_to_context(search_result):\n",
        "    return \"\\n\\n\".join(\n",
        "        [record.text for record in search_result]\n",
        "    )\n",
        "\n",
        "def search_results_to_text(search_result):\n",
        "    return [record.text for record in search_result]\n",
        "\n",
        "def answer_with_rag(\n",
        "    prompt: str,\n",
        "    system_prompt=None,\n",
        "    max_tokens=512,\n",
        "    client=nebius_client,\n",
        "    model=llama_8b_model,\n",
        "    table=None,\n",
        "    prettify=True,\n",
        "    temperature=0.6,\n",
        "    max_results=5,\n",
        "    verbose=False\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Generate an answer using RAG (Retrieval-Augmented Generation) with database search.\n",
        "\n",
        "    Args:\n",
        "        prompt: User's question or prompt\n",
        "        system_prompt: Instructions for the LLM\n",
        "        max_tokens: Maximum number of tokens in the response\n",
        "        client: OpenAI client instance\n",
        "        model: Model identifier\n",
        "        search_client: Search client instance (for example, Tavily)\n",
        "        prettify: Whether to format the output text\n",
        "        temperature: Temperature for response generation\n",
        "        search_depth: Depth of web search ('basic' or 'advanced')\n",
        "        verbose: whether to return the search results as well\n",
        "\n",
        "    Returns:\n",
        "        Generated response incorporating search results\n",
        "    \"\"\"\n",
        "    # Perform database search\n",
        "    max_stage_1_results = 10\n",
        "    if table:\n",
        "        try:\n",
        "            stage_1_results = search_table(table, prompt,\n",
        "                                           max_results=max_stage_1_results)\n",
        "            stage_1_results = search_results_to_text(stage_1_results)\n",
        "            ranked_results = reranker_model.rank(\n",
        "                prompt,\n",
        "                stage_1_results,\n",
        "                return_documents=True,\n",
        "                top_k=max_results\n",
        "            )\n",
        "\n",
        "            print(\"<<<<<< Reranked search results >>>>>\")\n",
        "            for result in ranked_results:\n",
        "                print(result)\n",
        "\n",
        "            search_results = [i[\"text\"] for i in ranked_results if i.get(\"text\")]\n",
        "\n",
        "        except (AttributeError, ValueError) as err:\n",
        "            print(err)\n",
        "            search_results = []\n",
        "    else:\n",
        "        search_results = []\n",
        "\n",
        "    # Construct messages with search results\n",
        "    messages = []\n",
        "\n",
        "    if system_prompt:\n",
        "        messages.append({\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_prompt\n",
        "        })\n",
        "\n",
        "    context = \"\\n\\n\".join(search_results)\n",
        "    # Add user prompt\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "            f\"\"\"Answer the following query using the context provided.\n",
        "\n",
        "            <context>\\n{context}\\n</context>\n",
        "\n",
        "            <query>{prompt}</query>\n",
        "            \"\"\"\n",
        "    })\n",
        "\n",
        "    # Generate completion\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    if prettify:\n",
        "        answer = prettify_string(completion.choices[0].message.content)\n",
        "    else:\n",
        "        answer = completion.choices[0].message.content\n",
        "\n",
        "    if verbose:\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"search_results\": search_results\n",
        "        }\n",
        "    else:\n",
        "        return answer"
      ],
      "metadata": {
        "id": "xrUTpK--g3CB",
        "cellView": "form"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")\n",
        "model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "results = answer_with_rag(\"\"\"How to quantize a model in 4 bits?\"\"\",\n",
        "               client=client,\n",
        "                model=model,\n",
        "               table=lance_table, verbose=True, max_results=4)\n",
        "print(results[\"answer\"])"
      ],
      "metadata": {
        "id": "99sH-wUAg3GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c200688-e970-46d7-9e41-519604c4d115"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<<<<< Reranked search results >>>>>\n",
            "{'corpus_id': 8, 'score': np.float32(0.6067128), 'text': 'Model optimization\\nQuantization using bitsandbytes\\nThe model can be loaded in 8 or 4 bits, greatly reducing the memory requirements while maintaining the performance of the original model. First make sure to install bitsandbytes, pip install bitsandbytes and make sure to have access to a GPU/accelerator that is supported by the library.\\n\\nbitsandbytes is being refactored to support multiple backends beyond CUDA. Currently, ROCm (AMD GPU) and Intel CPU implementations are mature, with Intel XPU in progress and Apple Silicon support expected by Q4/Q1. For installation instructions and the latest backend updates, visit this link.\\nWe value your feedback to help identify bugs before the full release! Check out these docs for more details and feedback links.'}\n",
            "{'corpus_id': 9, 'score': np.float32(0.5944168), 'text': 'Model optimization\\nQuantization using Bitsandbytes\\nThe model can be loaded in 8 or 4 bits, greatly reducing the memory requirements while maintaining the performance of the original model. First make sure to install bitsandbytes, pip install bitsandbytes and to have access to a GPU/accelerator that is supported by the library.\\n\\nbitsandbytes is being refactored to support multiple backends beyond CUDA. Currently, ROCm (AMD GPU) and Intel CPU implementations are mature, with Intel XPU in progress and Apple Silicon support expected by Q4/Q1. For installation instructions and the latest backend updates, visit this link.\\nWe value your feedback to help identify bugs before the full release! Check out these docs for more details and feedback links.'}\n",
            "{'corpus_id': 7, 'score': np.float32(0.5890541), 'text': 'bitsandbytes offers two main quantization features:\\n\\nLLM.int8() - An 8-bit quantization method that makes inference more accessible without significant performance degradation. Unlike naive quantization, LLM.int8() dynamically preserves higher precision for critical computations, preventing information loss in sensitive parts of the model.\\n\\nQLoRA - A 4-bit quantization technique that compresses models even further while maintaining trainability by inserting a small set of trainable low-rank adaptation (LoRA) weights.\\n\\nNote: For a user-friendly quantization experience, you can use the bitsandbytes community space.\\n\\nRun the command below to install bitsandbytes.'}\n",
            "{'corpus_id': 4, 'score': np.float32(0.4391899), 'text': '[!TIP]\\nRefer to the Quantization docs for more information about the different quantization backends available.\\n\\nTo lower memory usage even lower, you can quantize the model to 8-bit or 4-bit with bitsandbytes. Create a [BitsAndBytesConfig] with your desired quantization settings and pass it to the pipelines model_kwargs parameter. The example below quantizes a model to 8-bits.\\n\\nfrom transformers import pipeline, BitsAndBytesConfig\\nquantization_config = BitsAndBytesConfig(load_in_8bit=True)\\npipeline = pipeline(task=\"text-generation\", model=\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", model_kwargs={\"quantization_config\": quantization_config})'}\n",
            "To quantize a model in 4 bits using `bitsandbytes`, you can create a\n",
            "`BitsAndBytesConfig` with `load_in_4bit=True` and pass it to the `model_kwargs`\n",
            "parameter of the pipeline. Here is an example:\n",
            "\n",
            "```python\n",
            "from transformers import pipeline, BitsAndBytesConfig\n",
            "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
            "pipeline = pipeline(task=\"text-generation\",\n",
            "model=\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\",\n",
            "model_kwargs={\"quantization_config\": quantization_config})\n",
            "```\n",
            "\n",
            "This will load the model in 4-bit mode, reducing memory usage even further\n",
            "while maintaining trainability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the retrieved context pieces and their reranker scores:"
      ],
      "metadata": {
        "id": "OuinAg_FCOXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "ZYMFn5Lrg3In",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7660fdb6-ff28-48c9-cd45-83618d602797"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'To quantize a model in 4 bits using `bitsandbytes`, you can create a\\n`BitsAndBytesConfig` with `load_in_4bit=True` and pass it to the `model_kwargs`\\nparameter of the pipeline. Here is an example:\\n\\n```python\\nfrom transformers import pipeline, BitsAndBytesConfig\\nquantization_config = BitsAndBytesConfig(load_in_4bit=True)\\npipeline = pipeline(task=\"text-generation\",\\nmodel=\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\",\\nmodel_kwargs={\"quantization_config\": quantization_config})\\n```\\n\\nThis will load the model in 4-bit mode, reducing memory usage even further\\nwhile maintaining trainability.',\n",
              " 'search_results': ['Model optimization\\nQuantization using bitsandbytes\\nThe model can be loaded in 8 or 4 bits, greatly reducing the memory requirements while maintaining the performance of the original model. First make sure to install bitsandbytes, pip install bitsandbytes and make sure to have access to a GPU/accelerator that is supported by the library.\\n\\nbitsandbytes is being refactored to support multiple backends beyond CUDA. Currently, ROCm (AMD GPU) and Intel CPU implementations are mature, with Intel XPU in progress and Apple Silicon support expected by Q4/Q1. For installation instructions and the latest backend updates, visit this link.\\nWe value your feedback to help identify bugs before the full release! Check out these docs for more details and feedback links.',\n",
              "  'Model optimization\\nQuantization using Bitsandbytes\\nThe model can be loaded in 8 or 4 bits, greatly reducing the memory requirements while maintaining the performance of the original model. First make sure to install bitsandbytes, pip install bitsandbytes and to have access to a GPU/accelerator that is supported by the library.\\n\\nbitsandbytes is being refactored to support multiple backends beyond CUDA. Currently, ROCm (AMD GPU) and Intel CPU implementations are mature, with Intel XPU in progress and Apple Silicon support expected by Q4/Q1. For installation instructions and the latest backend updates, visit this link.\\nWe value your feedback to help identify bugs before the full release! Check out these docs for more details and feedback links.',\n",
              "  'bitsandbytes offers two main quantization features:\\n\\nLLM.int8() - An 8-bit quantization method that makes inference more accessible without significant performance degradation. Unlike naive quantization, LLM.int8() dynamically preserves higher precision for critical computations, preventing information loss in sensitive parts of the model.\\n\\nQLoRA - A 4-bit quantization technique that compresses models even further while maintaining trainability by inserting a small set of trainable low-rank adaptation (LoRA) weights.\\n\\nNote: For a user-friendly quantization experience, you can use the bitsandbytes community space.\\n\\nRun the command below to install bitsandbytes.',\n",
              "  '[!TIP]\\nRefer to the Quantization docs for more information about the different quantization backends available.\\n\\nTo lower memory usage even lower, you can quantize the model to 8-bit or 4-bit with bitsandbytes. Create a [BitsAndBytesConfig] with your desired quantization settings and pass it to the pipelines model_kwargs parameter. The example below quantizes a model to 8-bits.\\n\\nfrom transformers import pipeline, BitsAndBytesConfig\\nquantization_config = BitsAndBytesConfig(load_in_8bit=True)\\npipeline = pipeline(task=\"text-generation\", model=\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", model_kwargs={\"quantization_config\": quantization_config})']}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's set up a particular reranker and run the whole pipeline on our favourite query."
      ],
      "metadata": {
        "id": "slqeygZdCVJT"
      }
    }
  ]
}
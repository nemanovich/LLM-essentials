{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nemanovich/LLM-essentials/blob/main/week2_pratice_session.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this week's practice session we'll learn:\n",
        "\n",
        "- How to use LangChain, one of the most popular library to simplify LLM interaction;\n",
        "- How to add plugins to an LLM with LangChain;\n",
        "- How to interact with a database using an LLM."
      ],
      "metadata": {
        "id": "VUADqJGLqxKm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCb0dbvH6AQ0"
      },
      "source": [
        "# LangChain\n",
        "\n",
        "LangChain is a handy library which supplies a whole infrastucture around LLMs (both open source and available by API) allowing to quickly establish LLM-powered services. It can help you with many LLM related tasks, from prompt optimisation to creating multi-call LLM agents.\n",
        "\n",
        "Let's see how to use LangChain. First of all, download the library:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = open(\".open-ai-api-key\")\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get(\"open_ai_api_key\")"
      ],
      "metadata": {
        "id": "SGGArYZZ32aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dx0eA456AQ0"
      },
      "outputs": [],
      "source": [
        "!pip install openai langchain langchain_openai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The easiest thing you can do with LangChain is just calling an LLM.  We'll do it for OpenAI API:\n",
        "\n",
        "Note: The base model for OpenAI class is `text-davinci-003`, the significance of that will become apparent later"
      ],
      "metadata": {
        "id": "54DvPP6bHeRR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xspBOmsx6AQ1"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1etZ63Oi6AQ1",
        "outputId": "4e70b7f8-a63f-4d48-a83a-105eeb2da19b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " personality and behavior.\n",
            "\n",
            "Cats and dogs are two of the most popular pets in the world, but they have distinct differences in their personalities and behavior. Here are some key differences between cats and dogs:\n",
            "\n",
            "1. Personality and Independence\n",
            "\n",
            "Cats are known for their independent nature and can often be seen lounging around and doing their own thing. They are less likely to seek attention and affection from their owners and are content with their own company. On the other hand, dogs are social animals and crave attention and affection from their owners. They are loyal, loving, and thrive on human interaction.\n",
            "\n",
            "2. Trainability and Obedience\n",
            "\n",
            "Dogs are highly trainable and obedient animals. They are eager to please their owners and can be trained to perform a variety of tasks and commands. Cats, on the other hand, are less trainable and often do not respond well to obedience training. They are more independent and tend to do things on their own terms.\n",
            "\n",
            "3. Energy Levels\n",
            "\n",
            "Dogs are known for their high energy levels and need regular exercise and playtime to keep them happy and healthy. They require daily walks and playtime to release their energy. Cats, on the other hand, are naturally more sedentary and do not require as much exercise. They are content with short\n"
          ]
        }
      ],
      "source": [
        "print(llm.invoke(\n",
        "    \"What is the difference between cats and dogs? In two words:\"\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsUuk0l56AQ1"
      },
      "source": [
        "As you can see, the interface is already much simpler, compared to writing it on your own.\n",
        "\n",
        "LangChain also distinguishes between LLM's and Chat models.\n",
        "\n",
        "A difference is very subtle and mostly affect the format in which you pass data. LLM's are a pure text completion models, which means they input text and output text. Where is ChatModels work on a list of ChatMessages, which can be AIMessage, HumanMessage or SystemMessage (this difference we covered in week 1) and return an AIMessage.\n",
        "\n",
        "Newer OpenAI only implement chat interface, for example gpt-3.5-turbo, gpt-4, etc. This means, that you cannot use them as an LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mnscJPR6AQ1",
        "outputId": "fec28718-6ed2-40d9-ad4d-50352ef696a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Independence vs Loyalty', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 19, 'total_tokens': 24}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1c58a446-f292-446f-b4dc-2908813794ef-0', usage_metadata={'input_tokens': 19, 'output_tokens': 5, 'total_tokens': 24})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(name='gpt-4o-mini')\n",
        "chat.invoke([\n",
        "    HumanMessage(content=\"In two words what's the difference \"\\\n",
        "        \"between Cats and Dogs?\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Draw your attention to the fact that we received a `AIMessage` instead of a string"
      ],
      "metadata": {
        "id": "D3pUViKnaDlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basics"
      ],
      "metadata": {
        "id": "xmrvEGUREoHO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxQsTqfV6AQ2"
      },
      "source": [
        "#### Prompt templates\n",
        "\n",
        "A useful feature of LangChain is Prompt templates.\n",
        "\n",
        "If you need to use the same prompt structure with different parameters, prompt templates can save you from the text duplication. See, for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8rAkutU6AQ2",
        "outputId": "e8039d12-624c-4811-8133-33ded65e4a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the national cousine of Australia?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"What is the national cousine of {country}?\"\n",
        ")\n",
        "prompt.format(country=\"Australia\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPUcVsiP6AQ2"
      },
      "source": [
        "Now our imaginary user needs only to select a country instead of creating a whole prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chaining\n",
        "\n",
        "One of the main pillars of LangChain is the concept of chaining, that is of combining several LLM calls, external function calls, etc.\n",
        "\n",
        "Much like you combine layers in neural networks, but here we have a much more diverse set of tools.\n",
        "\n",
        "A very basic chain consists of prompt template and an LLM call. It's almost like a \"function\" for an LLM:"
      ],
      "metadata": {
        "id": "xT5bRZBfYfk3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnP3cxER6AQ2",
        "outputId": "b35d17f1-5eef-4dc7-f449-ef6655d1754f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThe national cuisine of Australia is often considered to be a fusion of British, Mediterranean, and Indigenous Australian influences. It includes dishes such as meat pies, fish and chips, roast lamb, and seafood. Other popular dishes include Vegemite on toast, pavlova, and Anzac biscuits. Australia is also known for its barbecue culture and love of fresh produce and seafood.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | llm | output_parser\n",
        "chain.invoke(\"Australia\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`StrOutputParser` here transforms output of our LLM, which in this case is in `messages`, in the format of a string. In case you'd ask for multiple output options, this parser give you the most likely one.\n",
        "\n",
        "Note by the way that, although we had a typo in the prompt template (\"cousine\" instead of \"cuisine\"), LLM managed to mitigate with it. You probably shouldn't rely on this too much, but generally LLMs, that are trained on data containing typos as well, can be able to cope with some amount of mistakes in the prompts."
      ],
      "metadata": {
        "id": "9S8kWoDEcZy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_model_response = llm.invoke(\"Hello, do you like cats?\")\n",
        "print(text_model_response)\n",
        "print(f\"Type: {type(text_model_response)}\")\n",
        "\n",
        "chat_response = chat.invoke(\"Hello, do you like cats?\")\n",
        "print(chat_response)\n",
        "print(f\"Type: {type(chat_response)}\")\n",
        "\n",
        "\n",
        "parsed_text_model_output = output_parser.invoke(text_model_response)\n",
        "print(parsed_text_model_output)\n",
        "print(type(parsed_text_model_output))\n",
        "\n",
        "parsed_chat_output = output_parser.invoke(chat_response)\n",
        "print(parsed_chat_output)\n",
        "print(type(parsed_chat_output))"
      ],
      "metadata": {
        "id": "QCS9lCgKVR-t",
        "outputId": "242df77a-9e5c-4397-d6b6-1a117c5010e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I am an AI and do not have the ability to like or dislike things like a human does. I am neutral towards cats.\n",
            "Type: <class 'str'>\n",
            "content=\"As a language model AI, I don't have personal preferences or feelings, so I don't have the ability to like or dislike anything. But cats are popular pets and are loved by many people for their playful and independent nature.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 14, 'total_tokens': 60}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-4b0d29e0-3193-4c0f-b92f-93cbd12a2211-0' usage_metadata={'input_tokens': 14, 'output_tokens': 46, 'total_tokens': 60}\n",
            "Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
            "\n",
            "\n",
            "I am an AI and do not have the ability to like or dislike things like a human does. I am neutral towards cats.\n",
            "<class 'str'>\n",
            "As a language model AI, I don't have personal preferences or feelings, so I don't have the ability to like or dislike anything. But cats are popular pets and are loved by many people for their playful and independent nature.\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sequential chain\n",
        "\n",
        "We can combine multiple calls in a simple sequential chain, where the output of one call become the input of another call."
      ],
      "metadata": {
        "id": "DPe71TMvacPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_prompt = PromptTemplate.from_template(\n",
        "    \"What is the capital of {country}?\"\n",
        ")\n",
        "first_chain = first_prompt | llm | output_parser\n",
        "\n",
        "second_prompt = PromptTemplate.from_template(\n",
        "    \"{city} is the capital of which country?\"\n",
        ")\n",
        "second_chain = second_prompt | llm | output_parser\n",
        "\n",
        "simple_sequential_chain = first_chain | second_chain"
      ],
      "metadata": {
        "id": "Cx4X1mCkaXY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intuitively now we should receive the same thing we inputted, let's try."
      ],
      "metadata": {
        "id": "7pmR19cKb3je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_sequential_chain.invoke(\"United Kingdom\")"
      ],
      "metadata": {
        "id": "5Yv8wkEZb_Uj",
        "outputId": "9e727146-e12c-4341-b95d-d4dd582d9b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThe capital of United Kingdom is London.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to make a more complicated chain, where outputs fill in specific variables, we'll have to use an `itemgetter`."
      ],
      "metadata": {
        "id": "IAj6rAHzdWod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "first_prompt = PromptTemplate.from_template(\n",
        "    \"Name a city of {country} starting with {letter}\",\n",
        ")\n",
        "first_chain = first_prompt | llm | output_parser\n",
        "\n",
        "second_prompt = PromptTemplate.from_template(\n",
        "    \"What is the main attraction in {city}?\"\n",
        ")\n",
        "second_chain = second_prompt | llm | output_parser\n",
        "\n",
        "sequential_chain = {\n",
        "    \"country\": itemgetter(\"country\"),\n",
        "    \"letter\": itemgetter(\"letter\"),\n",
        "    \"city\": first_chain\n",
        "} | second_chain | output_parser"
      ],
      "metadata": {
        "id": "3zWcl6-ad23j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In that case you'll have to pass input arguments as a dict."
      ],
      "metadata": {
        "id": "r7ZVAjufe6Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequential_chain.invoke({\"country\": \"France\", \"letter\": \"P\"})"
      ],
      "metadata": {
        "id": "6zKb6TXRe7B-",
        "outputId": "b869adf0-f632-446b-819e-cbe6ac33f0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThe main attraction in Paris is the Eiffel Tower.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Debugging\n",
        "\n",
        "As you can see we only get the output of the last chain. But what if we want to see what happened in the first one?"
      ],
      "metadata": {
        "id": "Q3dPu7-nINLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.tracers import ConsoleCallbackHandler\n"
      ],
      "metadata": {
        "id": "PaHMNUsaIL1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequential_chain.invoke(\n",
        "    {\"country\": \"France\", \"letter\": \"P\"},\n",
        "    config={'callbacks': [ConsoleCallbackHandler()]}\n",
        ")"
      ],
      "metadata": {
        "id": "VN-9TkUHIMal",
        "outputId": "3be000cd-9165-4a5d-aee0-33350b109087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"country\": \"France\",\n",
            "  \"letter\": \"P\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"country\": \"France\",\n",
            "  \"letter\": \"P\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"country\": \"France\",\n",
            "  \"letter\": \"P\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"France\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"country\": \"France\",\n",
            "  \"letter\": \"P\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"P\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"country\": \"France\",\n",
            "  \"letter\": \"P\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"country\": \"France\",\n",
            "  \"letter\": \"P\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableSequence > prompt:PromptTemplate] [3ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableSequence > llm:OpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Name a city of France starting with P\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableSequence > llm:OpenAI] [527ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\\n\\nParis\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 8,\n",
            "      \"completion_tokens\": 2,\n",
            "      \"total_tokens\": 10\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\\n\\nParis\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\n\\nParis\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city> > chain:RunnableSequence] [542ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\n\\nParis\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<country,letter,city>] [552ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"country\": \"France\",\n",
            "  \"letter\": \"P\",\n",
            "  \"city\": \"\\n\\nParis\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"country\": \"France\",\n",
            "  \"letter\": \"P\",\n",
            "  \"city\": \"\\n\\nParis\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"What is the main attraction in \\n\\nParis?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OpenAI] [820ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\\n\\nThere are several popular attractions in Paris, but the most iconic and famous is the Eiffel Tower. Other popular attractions include the Louvre Museum, Notre-Dame Cathedral, Arc de Triomphe, and the Champs-Élysées.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 9,\n",
            "      \"completion_tokens\": 51,\n",
            "      \"total_tokens\": 60\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\\n\\nThere are several popular attractions in Paris, but the most iconic and famous is the Eiffel Tower. Other popular attractions include the Louvre Museum, Notre-Dame Cathedral, Arc de Triomphe, and the Champs-Élysées.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\n\\nThere are several popular attractions in Paris, but the most iconic and famous is the Eiffel Tower. Other popular attractions include the Louvre Museum, Notre-Dame Cathedral, Arc de Triomphe, and the Champs-Élysées.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\\n\\nThere are several popular attractions in Paris, but the most iconic and famous is the Eiffel Tower. Other popular attractions include the Louvre Museum, Notre-Dame Cathedral, Arc de Triomphe, and the Champs-Élysées.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [3ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\n\\nThere are several popular attractions in Paris, but the most iconic and famous is the Eiffel Tower. Other popular attractions include the Louvre Museum, Notre-Dame Cathedral, Arc de Triomphe, and the Champs-Élysées.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.39s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\n\\nThere are several popular attractions in Paris, but the most iconic and famous is the Eiffel Tower. Other popular attractions include the Louvre Museum, Notre-Dame Cathedral, Arc de Triomphe, and the Champs-Élysées.\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThere are several popular attractions in Paris, but the most iconic and famous is the Eiffel Tower. Other popular attractions include the Louvre Museum, Notre-Dame Cathedral, Arc de Triomphe, and the Champs-Élysées.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b086ZL_6AQ2"
      },
      "source": [
        "### Task 1\n",
        "\n",
        "In this task we'll learn how to rewrite ChatGPT interaction code to LangChain.\n",
        "\n",
        "In the previous week we inplemented translate and summarise function. Rewrite it using `SequentialChain`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from operator import itemgetter\n",
        "\n",
        "llm = OpenAI()\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "summarise_prompt = PromptTemplate(\n",
        "    input_variables=['text'],\n",
        "    template=\"Write a short summary of the following text.\\n{text}\"\n",
        ")\n",
        "summarise_chain = summarise_prompt | llm | output_parser\n",
        "\n",
        "translate_prompt = PromptTemplate(\n",
        "    input_variables=['summary', 'target_language'],\n",
        "    template=\"Translate the following text to {target_language}:\\n{summary}\"\n",
        ")\n",
        "translate_chain = translate_prompt | llm | output_parser\n",
        "\n",
        "summarise_and_translate_chain = {\n",
        "    \"text\": itemgetter(\"text\"),\n",
        "    \"summary\": summarise_chain,\n",
        "    \"target_language\": itemgetter(\"target_language\")\n",
        "} | translate_chain | output_parser"
      ],
      "metadata": {
        "id": "VAJ_9prRcqCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article = open(\"wikipedia_article_japanese.txt\").read()\n",
        "\n",
        "summarise_and_translate_chain.invoke(\n",
        "    {'text': article, \"target_language\": \"English\"}\n",
        ")"
      ],
      "metadata": {
        "id": "KlveDg_YgCdX",
        "outputId": "a3cf47ec-e2a1-4c8d-d7b9-4f4cedd86891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'によっても異なる。\\n\\n\\nIn addition, products featuring paw pads are also commonly seen in adult goods.\\n\\nPaw pads are also used as trademarks for hanko (name stamps) and stamps (refer to Nekkiu).\\n\\nPaw pads are the raised and hairless part of the bottom of the feet of animals in the order Carnivora, and are officially called metatarsal pads. The paw pads have sections such as the palmar pad, digital pads, carpal pads, plantar pads, and toe pads, and they mainly serve to cushion the impact during walking. They can be found in animals such as cats, dogs, bears, weasels, rodents, and marsupials. The shape and softness of paw pads vary among individuals and can also differ depending on the environment they inhabit. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-iv_kRr6AQ3"
      },
      "source": [
        "## LangChain Agents and Memory\n",
        "\n",
        "In this part we'll explore two cool features of LangChain: **Agents** and **Memory**. You will learn how to:\n",
        "\n",
        "- access internet inside a chain;\n",
        "- remember the conversation history and adjust to it.\n",
        "\n",
        "**Agents** allow you to use tooling like web search, calling apis, math, python code etc. (they are known as \"Plugins\" in ChatBPT Web UI) to achive the goal of the given task.\n",
        "\n",
        "**Memory** allows you to keep a state of the conversation, just like what you see in the WebUI of ChatGPT.\n",
        "\n",
        "If you combine the two you can essentially get the same interface as ChatGPT WebUI has with plugins."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web search\n",
        "\n",
        "The are plenty of search engines available. We'll try DuckDuckGo, but feel free to use any other for your projects.\n",
        "\n",
        "Let's install the library."
      ],
      "metadata": {
        "id": "DWi_byUVn4EQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvnlZU7i6AQ3",
        "outputId": "b49e0e2b-e68c-4253-cdca-b14ee85e8da3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m128.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install duckduckgo_search langchain_community -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A search engine is a **tool**. Which is essentially a function with specific signature, that our LLM can use."
      ],
      "metadata": {
        "id": "F6XX-TydoMRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from langchain_community.tools import DuckDuckGoSearchRun, DuckDuckGoSearchResults\n",
        "\n",
        "results_tool = DuckDuckGoSearchResults()\n",
        "display(results_tool(\"What is the name of the cat from Shrek\"))\n",
        "\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "display(search_tool(\"What is the name of the cat from Shrek\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "nGlitpdqF6Ib",
        "outputId": "5baa0e76-b434-4ae5-8f22-91cf1cf9d11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"[snippet: Our beloved protagonists off the page, from the comedic genius of Mike Myers to the zestful Eddie Murphy, the spirited Cameron Diaz, and the regally villainous John Lithgow, lifted 'Shrek' from mere pixels to a cultural milestone. In the heart of 'Shrek's' colossal appeal lies its eclectic mix of misfit characters—a testament to the ..., title: List Of All Shrek Characters - Characters Database, link: https://charactersdb.com/list-all-shrek-characters/], [snippet: The first name on this list of Shrek characters is the man, or ogre, himself: Shrek. Shrek is the titular character of the franchise. ... Puss in Boots, or simply Puss, is an orange tabby cat. He carries a silver sword and wears a black cavalier hat, black boots, and a black belt. Spanish actor Antonio Banderas voiced Puss in the films ..., title: List of 35 Iconic Shrek Characters - Facts.net, link: https://facts.net/shrek-characters/], [snippet: Puss in Boots is a beloved character from the Shrek franchise that has captured the hearts of both children and adults alike. With his charming demeanor, iconic cat-like features, and witty one-liners, Puss in Boots has become one of the most memorable cartoon characters of all time. Originally introduced in Shrek 2, this swashbuckling feline quickly became a fan favorite, leading to the ..., title: 23 Facts About Puss In Boots (Shrek) - Facts.net, link: https://facts.net/lifestyle/entertainment/23-facts-about-puss-in-boots-shrek/], [snippet: Shrek is a 2001 American animated fantasy comedy film loosely based on the 1990 children's picture book of the same name by William Steig.Directed by Andrew Adamson and Vicky Jenson (in their feature directorial debuts) and written by Ted Elliott, Terry Rossio, Joe Stillman, and Roger S. H. Schulman, it is the first installment in the Shrek film series. ..., title: Shrek - Wikipedia, link: https://en.wikipedia.org/wiki/Shrek]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Explore the entire ensemble of 'Shrek' characters from the beloved 2001 Dreamworks classic. Enter the whimsical world of the ogre Shrek and his friends. Shrek characters are some of the most iconic characters in animation film history. Loved for their uniqueness, they appear in several films and spin-offs of the long-standing franchise starring the popular ogre. 23 Facts About Puss In Boots (Shrek) Puss in Boots is a beloved character from the Shrek franchise that has captured the hearts of both children and adults alike. With his charming demeanor, iconic cat-like features, and witty one-liners, Puss in Boots has become one of the most memorable cartoon characters of all time. Originally introduced in ... Shrek is a 2001 American animated fantasy comedy film loosely based on the 1990 children's picture book of the same name by William Steig. Directed by Andrew Adamson and Vicky Jenson (in their feature directorial debuts) and written by Ted Elliott, Terry Rossio, Joe Stillman, and Roger S. H. Schulman, it is the first installment in the Shrek film series. The film stars Mike Myers, Eddie Murphy ... Kenton April 2, 2024 Dive into the whimsical world of Shrek with this captivating Shrek trivia compilation! Whether you're a die-hard fan or simply intrigued by the green ogre's adventures, these questions and answers will test your knowledge and unravel the enchanting mysteries of Far Far Away. From Shrek's iconic swamp to the mischievous antics of Donkey and the schemes of Lord ...\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an agent, which uses this tool is pretty simple"
      ],
      "metadata": {
        "id": "LOg9Qw6BF4kY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbAIf4UF6AQ3",
        "outputId": "b3b3c7a4-cf4f-449e-dd0d-f59b5e3d9892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(name='gpt-4o-mini')\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=[search_tool], llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see it in action"
      ],
      "metadata": {
        "id": "Fhz-spICIdMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"What is the name of the cat from Shrek\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjlqzsirIXQP",
        "outputId": "86b7ee24-5d71-404e-c8df-cce194363974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find the name of the cat from Shrek\n",
            "Action: duckduckgo_search\n",
            "Action Input: \"Shrek cat name\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mExplore the entire ensemble of 'Shrek' characters from the beloved 2001 Dreamworks classic. Enter the whimsical world of the ogre Shrek and his friends. Shrek characters are some of the most iconic characters in animation film history. Loved for their uniqueness, they appear in several films and spin-offs of the long-standing franchise starring the popular ogre. Puss in Boots is a beloved character from the Shrek franchise that has captured the hearts of both children and adults alike. With his charming demeanor, iconic cat-like features, and witty one-liners, Puss in Boots has become one of the most memorable cartoon characters of all time. Originally introduced in Shrek 2, this swashbuckling feline quickly became a fan favorite, leading to the ... The cat in Shrek is called Puss in Boots, voiced by Antonio Banderas. He is a swashbuckling, charming and funny character who aids Shrek on his adventures. From princesses and villains to endearing sidekicks, one of these cat names inspired by Disney characters is sure to suit your favorite feline.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe cat from Shrek is named Puss in Boots.\n",
            "Final Answer: Puss in Boots\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the name of the cat from Shrek', 'output': 'Puss in Boots'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, agent not only chose to perform a web search, but also read the results and gave you the final answer.\n",
        "\n",
        "You can read more about how ReAct agents work [here](https://react-lm.github.io/)"
      ],
      "metadata": {
        "id": "gm3f2p3Ro-kP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FgQVMGK6AQ3"
      },
      "source": [
        "### Memory\n",
        "\n",
        "Memory allows an agent to memorize the previous interaction with the user and act according to it. Let's try to add memory and make a small conversation.\n",
        "\n",
        "We'll use the simplest construct called `ConversationBufferMemory` but you can actually use more complicated ones, which save conversation history to a database for example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onLblITM6AQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f23ff8a-fbae-43e9-d9aa-cb2f381f2797"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat_history': [HumanMessage(content=\"Hello, ChatGPT! How's your day?\"),\n",
              "  AIMessage(content=\"I'm doing well, thanks for asking!\")]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "memory.chat_memory.add_user_message(\"Hello, ChatGPT! How's your day?\")\n",
        "memory.chat_memory.add_ai_message(\"I'm doing well, thanks for asking!\")\n",
        "\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:\n",
        "- We used `memory_key` = 'chat_history', which is why memory returns us messages under that key\n",
        "- We used `return_messages` = True, which is why memory returns messages to us instead of concatenated strings."
      ],
      "metadata": {
        "id": "6sHjyOQvKPrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat history is explicitly present in the prompt as the `history` variable.\n",
        "\n",
        "Now, let's define the chain:\n"
      ],
      "metadata": {
        "id": "iMXcj7sRp97q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With LangChain you can initialise an agent with memory still in just a couple lines.\n",
        "You need to make sure to use an appropriate agent type (in this case the \"CHAT_CONVERSATION\" ReAct agent.\n",
        "\n",
        "Note: Admittedly the documentation for this is a bit chaotic, so you'll have to play a bit before you get a good result."
      ],
      "metadata": {
        "id": "Jn33rMjoKh5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "\n",
        "llm = ChatOpenAI(name='gpt-4o-mini')\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=[search_tool],\n",
        "    memory=memory,\n",
        "    llm=llm,\n",
        "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION ,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "LArn-hMIKnpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's to observe some memorization happening!"
      ],
      "metadata": {
        "id": "9AUQNjiZKvoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"What is the name of the cat from Shrek?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1H-v7_MKzBC",
        "outputId": "554a428f-712a-41d4-9a72-8456e547e322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"The name of the cat from Shrek is Puss in Boots.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the name of the cat from Shrek?',\n",
              " 'chat_history': [HumanMessage(content='What is the name of the cat from Shrek?'),\n",
              "  AIMessage(content='The name of the cat from Shrek is Puss in Boots.')],\n",
              " 'output': 'The name of the cat from Shrek is Puss in Boots.'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"How many sequels were there in this film?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMadDgVsK6Tc",
        "outputId": "cc29f07a-c7eb-4c1c-ca3b-4072e5487a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"There were three sequels in the Shrek film series: Shrek 2, Shrek the Third, and Shrek Forever After.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'How many sequels were there in this film?',\n",
              " 'chat_history': [HumanMessage(content='What is the name of the cat from Shrek?'),\n",
              "  AIMessage(content='The name of the cat from Shrek is Puss in Boots.'),\n",
              "  HumanMessage(content='How many sequels were there in this film?'),\n",
              "  AIMessage(content='There were three sequels in the Shrek film series: Shrek 2, Shrek the Third, and Shrek Forever After.')],\n",
              " 'output': 'There were three sequels in the Shrek film series: Shrek 2, Shrek the Third, and Shrek Forever After.'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector stores"
      ],
      "metadata": {
        "id": "al5Njtut6hgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(\"/content/langchain_vectorstore.png\", width=600)"
      ],
      "metadata": {
        "id": "0L3fkDRC6O3R",
        "outputId": "928b3876-cd88-4386-c0bc-3b3508a5bb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 600
            }
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the goals of this week is to create your own RAG-based app. **RAG** (**R**etrieval **A**ugmented **G**eneration) is a concept of supporting a generative model with some kind of a retrieval tool which allows to get more faithful results and less hallucinations. This is crucial when we need to supply our users with facts, for example, if we're creating a navigation tool for a company's internal wiki.\n",
        "\n",
        "Actually, we already touched upon RAG when we used DuckDuckGo. This time we'll retrieve data from a specific type of database - **vector store**.\n",
        "\n",
        "The idea behind vector storages is to represent data items as **embeddings** (real vectors). When we receive a search query, we also somehow make it into an embedding and look for its nearest neighbors in the vector space which can be done rather quickly if somewhat approximately. If your embedding model produces vectors with strong semantic information embedded into it, you can have very high quality retrieval.\n",
        "\n",
        "Vector storages emerged long before transformers, but, but because transformer models offer exceptional text understanding capabilities, using them to construct embeddings for vector storage systems is very popular. A typical AI-powered vector database query tool works like that:\n",
        "\n",
        "- An LLM reformulates user's prompt into a vector store query;\n",
        "- An embedding model is used to map the query into the database vector space;\n",
        "- Vector store returns several items whose embeddings are nearest neighbors of the query's embedding;\n",
        "- An LLM is used to process search results into a nice human readable output.\n",
        "\n",
        "In this practice session you'll getting acquainted with vector databases, and in the homework you'll assemble all the pipeline using LangChain.\n"
      ],
      "metadata": {
        "id": "B-kZXHDXxJFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are quite a few vector stores available. We will employ the system called [Faiss](https://github.com/facebookresearch/faiss). It is a state-of-the-art library made by Meta for creating vector databases, which is used by a lot of production solutions.\n",
        "\n",
        "We will use an IELTS essay dataset as a source of long texts, we want to search through."
      ],
      "metadata": {
        "id": "gR-55q0DBY1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please make sure to put your credentials in an appropriate location following the instruction here https://github.com/Kaggle/kaggle-api#api-credentials"
      ],
      "metadata": {
        "id": "aVtCbFzmhe5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle faiss-cpu tiktoken -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MRe2lUhg7gI",
        "outputId": "c7874f53-998e-449a-c715-e0244a84fa53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export KAGGLE_CONFIG_DIR=\"/content/\" && kaggle datasets download mazlumi/ielts-writing-scored-essays-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjMhdBS9hBTN",
        "outputId": "fcd1749f-448a-41da-84ff-5dc58e7740b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mazlumi/ielts-writing-scored-essays-dataset\n",
            "License(s): other\n",
            "Downloading ielts-writing-scored-essays-dataset.zip to /content\n",
            "  0% 0.00/674k [00:00<?, ?B/s]\n",
            "100% 674k/674k [00:00<00:00, 31.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ielts-writing-scored-essays-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SnJW885iRan",
        "outputId": "3ff83637-7813-4a3e-81fc-03905fc37028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ielts-writing-scored-essays-dataset.zip\n",
            "  inflating: ielts_writing_dataset.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the data:"
      ],
      "metadata": {
        "id": "YHlDfhDaB22Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas"
      ],
      "metadata": {
        "id": "lGGip06Wnybv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pandas.options.display.max_colwidth = 100\n",
        "reviews = pandas.read_csv(\"ielts_writing_dataset.csv\")\n",
        "reviews.head(2).dropna(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "H8ZiLTYS2oFt",
        "outputId": "3ca6d7f4-6e67-4956-a82d-0d77314a5574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Task_Type  \\\n",
              "0          1   \n",
              "1          2   \n",
              "\n",
              "                                                                                              Question  \\\n",
              "0  The bar chart below describes some changes about the percentage of people were born in Australia...   \n",
              "1  Rich countries often give money to poorer countries, but it does not solve poverty. Therefore, d...   \n",
              "\n",
              "                                                                                                 Essay  \\\n",
              "0  Between 1995 and 2010, a study was conducted representing the percentages of people born in Aust...   \n",
              "1  Poverty represents a worldwide crisis. It is the ugliest epidemic in a region, which could infec...   \n",
              "\n",
              "   Overall  \n",
              "0      5.5  \n",
              "1      6.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1fbeb34-2516-4464-8306-2470193e8e42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Task_Type</th>\n",
              "      <th>Question</th>\n",
              "      <th>Essay</th>\n",
              "      <th>Overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The bar chart below describes some changes about the percentage of people were born in Australia...</td>\n",
              "      <td>Between 1995 and 2010, a study was conducted representing the percentages of people born in Aust...</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Rich countries often give money to poorer countries, but it does not solve poverty. Therefore, d...</td>\n",
              "      <td>Poverty represents a worldwide crisis. It is the ugliest epidemic in a region, which could infec...</td>\n",
              "      <td>6.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1fbeb34-2516-4464-8306-2470193e8e42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1fbeb34-2516-4464-8306-2470193e8e42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1fbeb34-2516-4464-8306-2470193e8e42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d033589e-11cd-4239-a2ea-af539d809b13\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d033589e-11cd-4239-a2ea-af539d809b13')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d033589e-11cd-4239-a2ea-af539d809b13 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "reviews",
              "summary": "{\n  \"name\": \"reviews\",\n  \"rows\": 1435,\n  \"fields\": [\n    {\n      \"column\": \"Task_Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 402,\n        \"samples\": [\n          \"Providing a national system in a country where the unemployed receive a regular payment only encourages people not to seek work and puts an unreasonable strain on a country\\u2019s financial resources.Discuss this statement and give your opinion.Give reasons for your answer and include any relevant examples from your knowledge or experience.You should write at least 250 words.\",\n          \"The fact that enormous sums are paid for pieces of art is not acceptable at a time when many people around the world live in poverty. Discuss this statement and give your opinion.Give reasons for your answer and include any relevant examples from your knowledge or experience.You should write at least 250 words.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1274,\n        \"samples\": [\n          \"There are two possible ways to interprete the significance of history experience for our everyday life.\\nThe first point is to ignore the history experience. The main reason is based on the opinion that history never repeats. All historical persons that lived at the elder times never made their decisions in the conditions those surround us. The world has changed significantly. Technology, information, transport, medicine, human rights - all these important parts of our life has changed since the elder times. So, we can not directly copy the decisions of different problems of the elder times to our present life.\\nThe second point is to use the history experience in our present life. This opinion is based on observed samples of very similar intervals of history. At different time periods in different countries there were some events or historical processes being very similar. There are a lot of examples illustrating this thought. All countries of Medieval Europe and Asia past through the feodalism period. Then leaders of that counties decided that the feodalism is not the most effective way to control the country and annuled it. Nowadays we know that experience and, I believe, there will be no attempts to buld the feodalism again. The second example is the practice of conquestions. There were a lot of great conquerrors in the world's history: Alexander Macedonian, Caesar, Chinggis-khan, Napoleon, Gitler. All the listed persons conquerred big territories, their armies were very strong. But some time past and their empires were broken. Sometimes their enemies united against the conquerrors, sometimes they just died and their successors could not save the empires. But always the empires died. Nowadays we have no any signs of old borders of that empires. Actually all state borders are based on nations' borders, not on the old conquestions.\\nI think the second opinion is better. The reason is following. There are a lot of institutions in our life that we like. For example, human rights, property rights, education, medicine. All these institutions appeared as a result of historical experince. If our predecessors ignored that experience, we would never live in the modern society. In that case we would have no modern medicine and education, also we would live in the society with slaver. So, I think that we should thoroughly study the historical experience and use its conclusions in our present life.\",\n          \"The bar chart illustrates the number of minutes of telephone calls in Australia, made to various localities or devices, from 2001 to 2008.\\nOver the course of the eight years during which the data was sampled, it can be noted that the number of phone call minutes made to mobile phones has increased by the greatest proportion. In 2001, 2 billion minutes worth of phone call time was recorded. By 2008, this number had increased exponentially to 46 billion minutes.\\nThe bar chart illustrates that between the years 2001 and 2005, the number of phone calls made to local numbers gradually increased. However, from 2006, these calls decreased steadily until 2008, with a number that is only slightly higher than national and international calling minutes.\\nThe number of phone call minutes made to national as well as international locations consistently increased in the allocated time frame.\\nIt is also clear that local telephone calls account for the majority of phone calls made in Australia, and telephone calls made to mobile phones account for the least.\\nIn summary, the number of telephone call minutes made in Australia in different categories, varied during the years 2001 to 2008.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Examiner_Commen\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 62,\n        \"samples\": [\n          \"This essay covers the task. It has a good structure, however the conclusion paragraph is too big \\u2013 consider splitting it into 2 paragraphs, with the last one being the conclusion. As to the structure of sentences, there are several sentences that should be rephrased (see comments for suggestions). The grammar also needs some attention (see underlined in blue comments for details). Overall, this looks like a band 6.5 essay.\",\n          \"This essay is too short, 190 words instead of the minimum requirement of 250. It doesn\\u2019t say anything about girls being influenced by their mothers, which is also a part of the task \\u2013 therefore the task is only partially covered. The sentences are not complex enough, there are grammatical mistakes and inaccuracies (see comments underlined in blue). Overall, this looks like a Band 5.5 essay\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Task_Response\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coherence_Cohesion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lexical_Resource\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Range_Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0582370857889956,\n        \"min\": 1.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 14,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text splitters\n",
        "\n",
        "The length of the documents that we could store in a vector storage is limited by the context length of your models. The texts we work with are often longer, so we need **Text Splitters** to cut the texts into pieces.\n",
        "\n",
        "First of all, let's check out how big our documents are:"
      ],
      "metadata": {
        "id": "3kwgiluki-jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no truncation of text\n",
        "pandas.options.display.max_colwidth = 100_000_000"
      ],
      "metadata": {
        "id": "wbXyMhrJqx_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import re\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")"
      ],
      "metadata": {
        "id": "tkMFYx88jg9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows_as_single_string = reviews.apply(\n",
        "    lambda row: (re.sub(' +', ' ', row.to_string().replace(\"\\n\", \" \"))),\n",
        "    axis=1\n",
        ")\n",
        "max(map(lambda text: len(enc.encode(text)), rows_as_single_string))"
      ],
      "metadata": {
        "id": "fKB2-2kojQIL",
        "outputId": "c23e2b82-33ee-444f-c29f-c0976e299709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "772"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though this is less then 4096 max ChatGPT tokens, models typically don't undrestand long texts well enough, so it's better to split this item."
      ],
      "metadata": {
        "id": "tD5DesJhtTnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a document list for our database"
      ],
      "metadata": {
        "id": "7lVTnn9T29ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = rows_as_single_string.tolist()"
      ],
      "metadata": {
        "id": "xfFIKnJOusJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at a simple splitter called `CharacterTextSplitter`. It splits text on `separator` then gathers chunks based on `chunk size` as measured by a `length_function`. `chunk_overlap` controlls how much of the previous chunk we want to include in the next one for continuity.\n",
        "\n",
        "Let's see an example."
      ],
      "metadata": {
        "id": "Uj1ulK1txH0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\" \",\n",
        "    chunk_size=32,\n",
        "    chunk_overlap=4,\n",
        "    length_function=lambda text: len(enc.encode(text)),\n",
        ")"
      ],
      "metadata": {
        "id": "USA1UNLMxhq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "texts = text_splitter.create_documents(documents)\n",
        "display(texts[0])\n",
        "display(texts[1])\n",
        "display(texts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "tUdFxZ5Pxpj-",
        "outputId": "5d225f1c-d169-4e7e-a3fd-c25fef78f1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 108, which is longer than the specified 32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Document(page_content='Task_Type 1 Question The bar chart below describes some changes about the percentage of people')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Document(page_content='of people were born in Australia and who were born outside Australia living in urban,')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Document(page_content='in urban, rural and town between 1995 and 2010.Summarise the information by')"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`RecursiveCharacterTextSplitter` is very similar to `CharacterTextSplitter`, except for the splitting and gathering logic. It inputs a list of `separators` (the default is [\"\\n\\n\", \"\\n\", \" \", \"\"]), which it then used in the same order as in the list. That means that first we split paragraphs, then if they are bigger than `chunk_size` we split on sentences, and so on. This helps the chunks to be a bit more cohesive."
      ],
      "metadata": {
        "id": "wbPbrYHbwkql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=32,\n",
        "    chunk_overlap=4,\n",
        "    length_function=lambda text: len(enc.encode(text)),\n",
        "    add_start_index=True,\n",
        ")"
      ],
      "metadata": {
        "id": "0Hxas7VStTGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.create_documents(documents)\n",
        "display(texts[0])\n",
        "display(texts[1])\n",
        "display(texts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "eO3jYEO7uJ-z",
        "outputId": "849d5101-ae56-487f-faf5-5bf4f82615e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Document(metadata={'start_index': 0}, page_content='Task_Type 1 Question The bar chart below describes some changes about the percentage of people were born in Australia and who were born outside Australia living in urban, rural')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Document(metadata={'start_index': -1}, page_content='in urban, rural and town between 1995 and 2010.Summarise the information by selecting and reporting the main features and make comparisons where relevant.')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Document(metadata={'start_index': 288}, page_content='comparisons where relevant. Essay Between 1995 and 2010, a study was conducted representing the percentages of people born in Australia, versus people born outside')"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probably the most reasonable way to split is not by characters but by tokens using the model's tokenizer. LangChain supports creating a text splitter directly from tiktoken."
      ],
      "metadata": {
        "id": "LiQwGHMlyZZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=32,\n",
        "    chunk_overlap=4,\n",
        "    add_start_index=True\n",
        ")"
      ],
      "metadata": {
        "id": "bbmEZFUyx9KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.create_documents(documents)\n",
        "display(texts[0])\n",
        "display(texts[1])\n",
        "display(texts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "ze5hzd1ZyS0r",
        "outputId": "4645d2d7-ee51-4ca3-bdf2-1c4110b6f8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Document(metadata={'start_index': 0}, page_content='Task_Type 1 Question The bar chart below describes some changes about the percentage of people were born in Australia and who were born outside Australia living in urban, rural')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Document(metadata={'start_index': -1}, page_content='in urban, rural and town between 1995 and 2010.Summarise the information by selecting and reporting the main features and make comparisons where relevant. Essay Between')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Document(metadata={'start_index': 316}, page_content='Essay Between 1995 and 2010, a study was conducted representing the percentages of people born in Australia, versus people born outside Australia, living in urban, rural,')"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector database creation\n",
        "\n",
        "Let's create a database of segments of IELTS essays and examinator comments."
      ],
      "metadata": {
        "id": "seeLrywj3gq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=256,\n",
        "    chunk_overlap=16,\n",
        "    add_start_index=True\n",
        ")\n",
        "splitted_documents = text_splitter.create_documents(documents)\n",
        "db = FAISS.from_documents(splitted_documents, OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "jdvev55b39hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can perform similarity search using our embeddings"
      ],
      "metadata": {
        "id": "z5XatzjE4ovm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"An awesome essay about bar charts\"\n",
        "docs = db.similarity_search(query)\n",
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "FeErhxd_4F_n",
        "outputId": "898b2d66-8ec0-4e44-f595-3b724a9ae5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Task_Type 1 Question The bar charts below shows the number of visits to a community website in the first and second year of use.Summarize the information by selecting and reporting the main features and mae comparisons with relevant. Essay The bar chart illustrates the quantity of visits by the thousands paid to a community website within the first two years of use.\\\\nOverall, there is a greater upward trend from the second year of use compared to the first year of use. In addition to that, in both years the website undergoes a drastic fluctuation in numbers. It can be observed that initially in the month of September, number of visits in the first year of use are lower than second year of use, but numbers of the former subsequently surpasses the latter in the final month of August.\\\\nIn regards to the first year of use, quantity of visits increases from about 2000 visits in September to 10000 visits within 2 months and remains constant for another month. Following that, numbers plummet from December to February, reaching a low-point of less than approximately 500 visits. The numbers rise gradually from February onwards until it reaches it's highest at 15000 by August.\\\\nOn the other hand, during the second year of use, the number of visits rises sharply\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"A poorly written essay\"\n",
        "docs = db.similarity_search(query)\n",
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "nb0o2tO_5gcf",
        "outputId": "4054f89b-9b25-4cd5-d0f6-224fe5704e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'but you must offer more arguments regarding why you agree or disagree. There are many spelling, punctuation and article errors. The essay is easy to follow but has the appearance of the writer running short of time. Task_Response NaN Coherence_Cohesion NaN Lexical_Resource NaN Range_Accuracy NaN Overall 5.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specific OpenAI api capabilities\n",
        "\n",
        "Since the creation of LangChain, OpenAI's api actually added a lot of creature comforts on it's own, so some of the funcitonality is being duplicated a bit now.\n"
      ],
      "metadata": {
        "id": "yQQquP4vWfrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structured outputs\n",
        "\n",
        "Modern LLMs support outputing in a specific format, for example we can use \"JSON mode\" to force outputs to be in JSON fromat."
      ],
      "metadata": {
        "id": "99stviAwWjTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = open(\".open-ai-api-key\")\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get(\"open_ai_api_key\")\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "non_json_output = client.chat.completions.create(\n",
        "    messages=[{'role': 'user', 'content': 'Design a role play character\\'s name, class and a short description'}],\n",
        "    model=\"gpt-4o-mini\",\n",
        ").choices[0].message.content\n",
        "print(non_json_output)\n",
        "\n",
        "json_output = client.chat.completions.create(\n",
        "    messages=[{'role': 'user', 'content': 'Design a role play character\\'s name, class and a short description in json format'}],\n",
        "    model=\"gpt-4o-mini\",\n",
        "    response_format={\"type\": \"json_object\"}\n",
        ").choices[0].message.content\n",
        "print(json_output)"
      ],
      "metadata": {
        "id": "ryrB2UfDXitX",
        "outputId": "11cf2f96-e00d-4fef-986a-7ce17b90abbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Character Name:** Elowen Thistlebloom\n",
            "\n",
            "**Class:** Feybinder\n",
            "\n",
            "**Description:** Elowen is a mysterious Feybinder from the Enchanted Glade, where the veil between the mortal realm and the Feywild is thin. She has ethereal, luminescent green hair that cascades down her back like the vines in her enchanted forest home. Her skin shimmers like moonlight, and her deep emerald eyes reflect the secrets of the woods. Clad in flowing robes woven from petals and leaves, Elowen carries a staff adorned with crystals that pulse with magic.\n",
            "\n",
            "A master of nature's whispers, Elowen communicates with the spirits of the forest and harnesses the power of the Fey to aid her allies or confound her enemies. With a quick smile and a mischievous glint in her eye, she often dances on the edge of chaos, favoring unpredictable spells that weave enchantment and illusion. While she appears gentle and whimsical, there's a fierce loyalty that drives her to protect her home and its inhabitants at all costs. Elowen seeks adventure to further her connection with the Fey and discover the mysteries of the world beyond the glade.\n",
            "{\n",
            "  \"character\": {\n",
            "    \"name\": \"Elara Moonshadow\",\n",
            "    \"class\": \"Druid\",\n",
            "    \"description\": \"Elara Moonshadow is a wise and enigmatic druid hailing from the ancient Whispering Woods. With long, flowing silver hair and deep emerald eyes, she has an ethereal presence that draws the attention of both allies and foes. Elara is deeply connected to nature and possesses the ability to shapeshift into various animal forms. She wields a staff adorned with glowing crystal vines, and her spells revolve around healing, nature manipulation, and summoning woodland creatures to aid her in battle. Fierce yet nurturing, Elara seeks to protect the balance of the natural world.\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is useful, because that'll make it much easier for you later to parse the outputs:"
      ],
      "metadata": {
        "id": "1T5XjuVIZJqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "json.loads(json_output)"
      ],
      "metadata": {
        "id": "HOFWiZMFZNz_",
        "outputId": "0a33117e-7a5c-41b8-ce30-f90402180aa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'character': {'name': 'Elara Moonshadow',\n",
              "  'class': 'Druid',\n",
              "  'description': 'Elara Moonshadow is a wise and enigmatic druid hailing from the ancient Whispering Woods. With long, flowing silver hair and deep emerald eyes, she has an ethereal presence that draws the attention of both allies and foes. Elara is deeply connected to nature and possesses the ability to shapeshift into various animal forms. She wields a staff adorned with glowing crystal vines, and her spells revolve around healing, nature manipulation, and summoning woodland creatures to aid her in battle. Fierce yet nurturing, Elara seeks to protect the balance of the natural world.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can go another step further and actually define a `pydantic` model for our outputs:"
      ],
      "metadata": {
        "id": "eB0ImQP5ZjzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class CharacterProfile(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "    special_skills: List[str]\n",
        "    traits: List[str]\n",
        "    character_class: str\n",
        "    origin: str\n",
        "\n",
        "completion = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Design a role play character\"}\n",
        "    ],\n",
        "    response_format=CharacterProfile,\n",
        ")\n",
        "\n",
        "completion.choices[0].message.parsed"
      ],
      "metadata": {
        "id": "r_jEZ2wiZpD_",
        "outputId": "33974cdb-b41d-42b1-cd2a-e9647e7e0856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharacterProfile(name='Elara Nightshade', age=27, special_skills=['Archery', 'Potion Brewing', 'Stealth Navigation'], traits=['Loyal', 'Adaptable', 'Cunning'], character_class='Ranger', origin='Elderwood Forest')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So no we have predefined format of outputs, which is easy to work with."
      ],
      "metadata": {
        "id": "FfXwmnGeacJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAPI Tool Usage\n",
        "\n",
        "We can use tools in OpenAI api as well. Let's see how we can use web search with just the api:"
      ],
      "metadata": {
        "id": "nGZM-mwVNVxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install duckduckgo_search -q"
      ],
      "metadata": {
        "id": "RDVewymxaiFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from duckduckgo_search import DDGS\n",
        "\n",
        "search = DDGS()\n",
        "search.text(keywords=\"What is the capital of France\", max_results=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHy65SEdOA4A",
        "outputId": "83008828-34db-4f55-c569-18bd84e3aa0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'What is the Capital of France? - WorldAtlas',\n",
              "  'href': 'https://www.worldatlas.com/articles/what-is-the-capital-of-france.html',\n",
              "  'body': 'Learn about Paris, the largest and most populous city in France, and its history, geography, economy, tourism, and administration. Find out why Paris is called the City of Light and the City of Love.'},\n",
              " {'title': 'Paris - Wikipedia',\n",
              "  'href': 'https://en.wikipedia.org/wiki/Paris',\n",
              "  'body': 'Paris is a global centre of finance, diplomacy, culture, and gastronomy, with an estimated population of 2.1 million in 2023. It has many famous landmarks, museums, and historical districts, and is home to several international organizations and sports clubs.'},\n",
              " {'title': 'Paris | Definition, Map, Population, Facts, & History | Britannica',\n",
              "  'href': 'https://www.britannica.com/place/Paris',\n",
              "  'body': \"Paris, city and capital of France, located along the Seine River, in the north-central part of the country. Paris is one of the world's most important and attractive cities, famed for its gastronomy, haute couture, painting, literature, and intellectual community. Learn more about Paris in this article.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can define a `tool` description for OpenAI's client, so that the model knows how to use it.\n",
        "\n",
        "We will only expose `keywords` parameter.\n",
        "\n",
        "We also need to write short descriptions to explain what the tool and the parameter are for.\n",
        "\n",
        "Tool usage is sort of an extension of \"JSON mode\" because in the end we get a dict of parameters, parsed from the JSON."
      ],
      "metadata": {
        "id": "wqz5uYsDa4l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"search-text\",\n",
        "            \"description\": \"Retrieves results from DuckDuckGo web search\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"keywords\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"What you search for\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"keywords\"],\n",
        "            },\n",
        "        }\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"If you are asked about the factual information, create a function call instead. If you already searched, use the results to give an answer.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"What is the name of the cat from Shrek?\"})\n",
        "chat_response = client.chat.completions.create(\n",
        "    messages=messages, tools=tools, model=\"gpt-4o-mini\"\n",
        ")\n",
        "chat_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfkpK-EqNthN",
        "outputId": "527c8ffd-ab09-4836-ab00-6d1dd3c6972d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9y1xcfee38B7ePoOMNnk7j0nrZpDY', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_NQg9D6uDQmn5GJRfEMSO623T', function=Function(arguments='{\"keywords\":\"cat from Shrek name\"}', name='search-text'), type='function')]))], created=1724094244, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_48196bc67a', usage=CompletionUsage(completion_tokens=18, prompt_tokens=91, total_tokens=109))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can extract the function usage output from the result"
      ],
      "metadata": {
        "id": "TDoc1RE-bpUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response.choices[0].message.tool_calls[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9WJEQd2QhI0",
        "outputId": "502f5f11-e006-41a8-8c5c-5584aba61ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletionMessageToolCall(id='call_NQg9D6uDQmn5GJRfEMSO623T', function=Function(arguments='{\"keywords\":\"cat from Shrek name\"}', name='search-text'), type='function')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now based on this functionality, we can create a function to answer using web search."
      ],
      "metadata": {
        "id": "BrdyPXNUQIzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def chat_completion_with_web_search(query):\n",
        "    ready_to_answer = False\n",
        "    messages = []\n",
        "    messages.append({\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"If you are asked about the factual information, \"\\\n",
        "        \"create a search function call instead of answering directly.\"\\\n",
        "        \"If you already searched, use the results to give an answer.\"})\n",
        "    messages.append({\"role\": \"user\", \"content\": query})\n",
        "    while not ready_to_answer:\n",
        "        chat_response = client.chat.completions.create(\n",
        "            messages=messages, tools=tools, model=\"gpt-4o-mini\"\n",
        "        ).choices[0].message\n",
        "        messages.append(chat_response.to_dict())\n",
        "        if chat_response.tool_calls:\n",
        "            if chat_response.tool_calls[0].function.name == \"search-text\":\n",
        "                print(\"Searching the web\")\n",
        "                call_arguments = json.loads(\n",
        "                    chat_response.tool_calls[0].function.arguments\n",
        "                )\n",
        "                print(f\"Call arguments: {call_arguments}\")\n",
        "                web_results = str(search.text(**call_arguments))\n",
        "                print(f\"Results: {web_results}\")\n",
        "                messages.append({\n",
        "                    \"role\": \"tool\",\n",
        "                    \"content\": web_results,\n",
        "                    \"tool_call_id\": chat_response.tool_calls[0].id\n",
        "                })\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported tool {chat_response.tool_calls[0].function.name}\")\n",
        "        else:\n",
        "            print(\"Answering the question\")\n",
        "            messages.append({\"role\": \"assistant\", \"content\": chat_response.content})\n",
        "            ready_to_answer = True\n",
        "    return messages[-1]['content']"
      ],
      "metadata": {
        "id": "NHJ1dh4TQFwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion_with_web_search(\"What is the name of the cat from Shrek?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "QzJCAwm7Qg-v",
        "outputId": "fb3c6fb5-b179-4eb8-bfc7-b9af88ab7c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching the web\n",
            "Call arguments: {'keywords': 'cat name Shrek'}\n",
            "Results: [{'title': 'Puss in Boots (Shrek) - Wikipedia', 'href': 'https://en.wikipedia.org/wiki/Puss_in_Boots_(Shrek)', 'body': \"Puss in Boots, or simply Puss, is a main character in the Shrek franchise.He made his first appearance in the film Shrek 2 (2004), soon becoming Shrek's partner and helper (alongside Donkey).In the film Shrek the Third (2007), Puss helps Shrek find the heir to the throne of the Far Far Away Kingdom. The film Shrek Forever After (2010) is primarily set in an alternate universe, where Puss is ...\"}, {'title': 'Puss in Boots | WikiShrek | Fandom', 'href': 'https://shrek.fandom.com/wiki/Puss_in_Boots', 'body': 'Puss in Boots, often referred to as just Puss (re-christened Pickles), briefly, is a ginger-striped cat that is skilled with a sword and whose name is derived from the hat and boots he wears. He first appeared as a bounty hunter but later became Shrek\\'s faithful sidekick, until leaving to become the \"fearless hero\" he always believed himself to be. Loosely based on the fairytale character Puss ...'}, {'title': 'Puss in Boots | Dreamworks Animation Wiki | Fandom', 'href': 'https://dreamworks.fandom.com/wiki/Puss_in_Boots', 'body': 'I am Puss in Boots, and my name... would become... LEGEND.Puss in Boots. Puss in Boots, or simply Puss, is one of the tritagonists in the Shrek franchise and the titular protagonist of the franchise of the same name. He is a cat loosely based on the fairy tale character of the same name with the boots, hat, cape, and sword commonly associated with the fairy tale. Puss in Boots was born and ...'}, {'title': \"What's the name of the cat in Shrek? - YouTube\", 'href': 'https://www.youtube.com/watch?v=ne8gPBVHV5Q', 'body': 'Discover the Legendary Feline of Shrek: Puss in Boots! Unveil the name of the cat that stole our hearts in the beloved Shrek franchise. With his swashbucklin...'}, {'title': 'Puss in Boots | Heroes Wiki | Fandom', 'href': 'https://hero.fandom.com/wiki/Puss_in_Boots_(Shrek)', 'body': \"Puss in Boots, or simply known as Puss, is a major character in the Shrek franchise, and the titular main protagonist of the spin-off franchise of the same name. He is a swashbuckling ginger cat from Spain who has embarked on several daring adventures, becoming a legendary hero wherever he goes. He was initially hired by King Harold to assassinate Shrek under the Fairy Godmother's orders, but ...\"}, {'title': 'Puss in Boots (character) | DreamWorks Animation Wiki | Fandom', 'href': 'https://dreamworks-animation.fandom.com/wiki/Puss_in_Boots_(character)', 'body': \"Puss in Boots, also simply known as Puss, is a major character in the Shrek franchise, and the titular main protagonist of the spin-off franchise of the same name. He is a swashbuckling ginger cat from Spain who has embarked on several daring adventures, becoming a legendary hero wherever he goes. He was initially hired by King Harold to assassinate Shrek under the Fairy Godmother's orders ...\"}, {'title': 'Puss in Boots - Wikipedia', 'href': 'https://en.wikipedia.org/wiki/Puss_in_Boots', 'body': 'In folkloristics, Puss in Boots is classified as Aarne-Thompson-Uther ATU 545B, \"Puss in Boots\", a subtype of ATU 545, \"The Cat as Helper\". [5] Folklorists Joseph Jacobs and Stith Thompson point that the Perrault tale is the possible source of the Cat Helper story in later European folkloric traditions. [6] [7] Similarly, Frisian professor Jurjen van der Kooi noted that variants from oral ...'}, {'title': 'Puss in Boots | DreamWorks Animation Wiki | Fandom', 'href': 'https://dreamworksanimation.fandom.com/wiki/Puss_in_Boots', 'body': \"Puss in Boots, also simply known as Puss, is a major character in the Shrek franchise, and the titular main protagonist of the spin-off franchise of the same name. He is a swashbuckling ginger cat from Spain who has embarked on several daring adventures, becoming a legendary hero wherever he goes. He was initially hired by King Harold to assassinate Shrek under the Fairy Godmother's orders ...\"}, {'title': 'Puss in Boots | Universal Studios Wiki | Fandom', 'href': 'https://universalstudios.fandom.com/wiki/Puss_in_Boots', 'body': \"Puss in Boots is a main character in the Shrek franchise and the titular protagonists of its spin-off franchise of the same name. He is a swashbuckling ginger cat from Spain who has embarked on several daring adventures, becoming a legendary hero wherever he goes. He was initially hired by King Harold to assassinate Shrek under the Fairy Godmother's orders, but abandoned this hit and became ...\"}, {'title': 'Puss in Boots (Shrek) - Simple English Wikipedia, the free encyclopedia', 'href': 'https://simple.wikipedia.org/wiki/Puss_in_Boots_(Shrek)', 'body': \"Puss in Boots is a main character in the Shrek franchise, also being portrayed as the title character and protagonist of the movie Puss in Boots (2011). He made his first appearance in the movie Shrek 2 (2004), soon becoming Shrek's partner and helper (alongside Donkey).In the movie Shrek the Third (2007), Puss helps Shrek find the heir to the throne of the Far Far Away Kingdom.\"}, {'title': 'Cat | WikiShrek | Fandom', 'href': 'https://shrek.fandom.com/wiki/Cat', 'body': 'Cats are a species in the Shrek universe. Some of them, notably Puss in Boots, possess human-like intelligence and are able to talk. Others behave like real-life cats. They all have sharp claws (with the exception of Kitty, whose paws are very soft and claw-less after being declawed by her former owners) to defend themselves and are very agile. Gato is the Spanish word for cat; gatito is the ...'}, {'title': \"What Is The Name Of Shrek's Cat? | Pawfect Names\", 'href': 'https://pawfectnames.com/know/shrek-cat-name/', 'body': \"Shrek's cat is named Puss in Boots. This character is a major player in the Shrek franchise, and has even had his own spin-off movie. Puss in Boots is a swashbuckling feline who is skilled in sword fighting and has a charming personality. He is voiced by Antonio Banderas in the films. The character of Puss in Boots has become very popular since ...\"}, {'title': '23 Facts About Puss In Boots (Shrek) - Facts.net', 'href': 'https://facts.net/lifestyle/entertainment/23-facts-about-puss-in-boots-shrek/', 'body': 'Puss in Boots is a beloved character from the Shrek franchise that has captured the hearts of both children and adults alike. With his charming demeanor, iconic cat-like features, and witty one-liners, Puss in Boots has become one of the most memorable cartoon characters of all time. Originally introduced in Shrek 2, this swashbuckling feline quickly became a fan favorite, leading to the ...'}, {'title': 'Puss in Boots: The Last Wish Cast and Character Guide - Collider', 'href': 'https://collider.com/puss-in-boots-the-last-wish-cast-charactersl/', 'body': 'One day, the King of Far, Far, Away ( John Cleese ), paid Puss to deal with his controversial son-in-law, Shrek. He takes the contract but quickly discovers that Shrek and his companion Donkey ...'}, {'title': 'List of Shrek (franchise) characters - Wikipedia', 'href': 'https://en.wikipedia.org/wiki/List_of_Shrek_(franchise)_characters', 'body': 'Shrek (voiced by Mike Myers and Michael Gough as his official voice in the video games) is a large, grumpy yet caring green ogre and the lead character in all of the Shrek films. Chris Farley was originally cast to be the voice of Shrek, but he died before he could complete his voice work. He had finished 85-95% of his lines. [1] [2]Donkey (voiced by Eddie Murphy in the films, Mark Moseley in ...'}, {'title': 'List of 35 Iconic Shrek Characters - Facts.net', 'href': 'https://facts.net/shrek-characters/', 'body': 'The first name on this list of Shrek characters is the man, or ogre, himself: Shrek. Shrek is the titular character of the franchise. ... A popular fan-favorite among Shrek characters is Puss in Boots. Puss in Boots, or simply Puss, is an orange tabby cat. He carries a silver sword and wears a black cavalier hat, black boots, and a black belt ...'}, {'title': 'Shrek cast and characters — where are they now? - The Digital Fix', 'href': 'https://www.thedigitalfix.com/shrek/cast', 'body': \"Let's look at the characters, actors, and where they are now. The main Shrek cast list: Mike Myers as Shrek. Eddie Murphy as Donkey. Cameron Diaz as Princess Fiona. Antonio Banderas as Puss in Boots. Conrad Vernon as Gingerbread Man. Cody Cameron as Pinocchio/The Three Little Pigs. Aron Warner as Big Bad Wolf.\"}, {'title': '100+ Cartoon Cat Names Inspired by Your Favorite Shows - Rover.com', 'href': 'https://www.rover.com/blog/cartoon-cat-names/', 'body': 'Names Inspired By Male Cartoon Cats. Azrael - Smurfs. Babbit and Catstello - Merrie Melodies. Banjo - Banjo the Woodpile Cat. Beans - Merrie Melodies. Beerus - Dragon Ball Z: Battle of Gods. Bonkers D. Bobcat - Bonkers. Branya - The Comic Artist and Assistants. Butch - Tom and Jerry.'}, {'title': 'List Of All Shrek Characters - Characters Database', 'href': 'https://charactersdb.com/list-all-shrek-characters/', 'body': \"Our beloved protagonists off the page, from the comedic genius of Mike Myers to the zestful Eddie Murphy, the spirited Cameron Diaz, and the regally villainous John Lithgow, lifted 'Shrek' from mere pixels to a cultural milestone. In the heart of 'Shrek's' colossal appeal lies its eclectic mix of misfit characters—a testament to the ...\"}, {'title': '185 Cat Names From Movies for Your Feline Superstar - Daily Paws', 'href': 'https://www.dailypaws.com/cats-kittens/cat-names/cat-names-from-movies', 'body': 'Cat names from movies might be inspired by classic kitties such as Berlioz from The Aristocats to bold characters, such as Katniss from The Hunger Games. ... Puss in Boots (Shrek 2) Richard Parker (Life of Pi) Shang-Chi (Shang-Chi and the Legend of the Ten Rings) Smokey (Stuart Little) Tai Lung (Kung Fu Panda)'}, {'title': 'Shrek (film series) - IMDb', 'href': 'https://www.imdb.com/list/ls041070883/', 'body': '2011 1h 30m PG. 6.6 (195K) Rate. 65 Metascore. An outlaw cat, his childhood egg-friend, and a seductive thief kitty set out in search for the eggs of the fabled Golden Goose to clear his name, restore his lost honor, and regain the trust of his mother and town. Director Chris Miller Stars Antonio Banderas Salma Hayek Zach Galifianakis.'}, {'title': 'All Of The Shrek Movies (Including Puss In Boots), Ranked - MSN', 'href': 'https://www.msn.com/en-us/movies/news/all-of-the-shrek-movies-including-puss-in-boots-ranked/ar-AA1ozPnp', 'body': 'The Shrek films have certainly left an impact on the world of animation throughout their two-decade run.Now, Shrek 5 is confirmed, and yes, I am just as excited as most of my generation, who grew ...'}, {'title': '160+ Cat Names From Movies for Every Pet Personality', 'href': 'https://www.lovetoknowpets.com/cats/160-cat-names-from-movies-every-pet-personality', 'body': 'Shrek Cat Name . The cat in the Shrek franchise is Puss in Boots. Antonio Banderas is the voice actor for the animated character featured in Shrek 2, Shrek the Third, and Shrek Forever After. Hocus Pocus Cat Name . The cat in the movie Hocus Pocus is named Binx. The cat is a 3-D cat head designed by a computer program.'}, {'title': \"Shrek's 30 Funniest Quotes - Screen Rant\", 'href': 'https://screenrant.com/shrek-funniest-quotes/', 'body': 'Shrek made DreamWorks Animation a household name, and, over 20 years and four films later, they remain as influential as ever. ... In Shrek the Third, Shrek, Donkey, and Puss in Boots learn that the future King Arthur is in Worcestershire. As Donkey pontificates about what the place may be, Shrek notes a familiar feeling, ...'}, {'title': 'Name of cat in Shrek? - Answers', 'href': 'https://www.answers.com/zoology/Name_of_cat_in_Shrek', 'body': 'Best Answer. Puss In Boots. Wiki User. ∙ 15y ago. More answers. AnswerBot. ∙ 3d ago. The cat in Shrek is called Puss in Boots, voiced by Antonio Banderas. He is a swashbuckling, charming and ...'}, {'title': 'Cat for adoption - Shrek, a Domestic Short Hair in Newport News, VA ...', 'href': 'https://www.petfinder.com/cat/shrek-72748850/va/newport-news/chasin-tails-kitten-nursery-no-more-chasin-tails-spay-neuter-clinic-va825/', 'body': \"Meet Shrek, a Domestic Short Hair Cat for adoption, at Chasin' Tails Kitten Nursery (No More Chasin Tails Spay/neuter Clinic) in Newport News, VA on Petfinder. Learn more about Shrek today. ... First name Last name Email Phone Number (Optional) Country. ZIP code Petfinder Is Available Only In Specific Regions ...\"}, {'title': 'Upcoming animated movies of 2026 | Lifestyle Asia Thailand', 'href': 'https://www.lifestyleasia.com/bk/entertainment/movies/upcoming-animated-movies-in-2026-shrek-5-toy-story-5-frozen-3/', 'body': \"Prominent names like Dr. Seuss' The Cat in The Hat is slated for release on 6 March, followed by Toy Story 5 on 19 June, Shrek 5 on 1 July and a Walt Disney Animation Studios' gem Frozen 3 towards the latter half of 2026. Truly, it seems like 'tis the time for animated genius. The 2026 calendar has more highly anticipated titles scheduled.\"}, {'title': '100 Calico Cat Names for Your Beautiful Kitty - The Spruce Pets', 'href': 'https://www.thesprucepets.com/calico-cat-names-7094992', 'body': \"Surprisingly to some, calico isn't actually a breed of cat but rather the name of a color pattern, so many different breeds can be calico cats. These felines are almost always female, too, due to the chromosomal makeup that determines the color variation of the coat.\"}, {'title': \"Trump vs. Harris magnifies America's generational and cultural divides\", 'href': 'https://www.washingtonpost.com/elections/2024/08/14/trump-harris-voters-generation-culture-election-2024/', 'body': 'There were green shirts and buttons with Harris\\'s name in the blurred font of \"Brat.\" In Atlanta, the crowd\\'s excitement reached new heights when rapper Megan Thee Stallion took the stage .'}]\n",
            "Answering the question\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The cat from Shrek is named **Puss in Boots**, often simply referred to as Puss. He is a swashbuckling feline character who first appeared in the film *Shrek 2* (2004) and has since become a beloved character in the franchise.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latency\n",
        "\n",
        "Depending on the model (size of the model), provider and some specific parameters, the latency of completion calls can vary a lot.\n",
        "\n",
        "Let's write a small function to measure latency and test it on OpenAI's and Anthropic's models."
      ],
      "metadata": {
        "id": "T62MyF8F26PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai anthropic -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-T8m7PN753Ki",
        "outputId": "b130c6b3-6299-439a-dc31-209f50853d59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/891.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m890.9/891.5 kB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.5/891.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def measure_execution_time(func, n, *args, **kwargs):\n",
        "    latencies = []\n",
        "\n",
        "    for _ in range(n):\n",
        "        start_time = time.time()\n",
        "        func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "\n",
        "        latency = end_time - start_time\n",
        "        latencies.append(latency)\n",
        "\n",
        "    latencies = np.array(latencies)\n",
        "\n",
        "    stats = {\n",
        "        'average_latency': np.mean(latencies),\n",
        "        'max_latency': np.max(latencies),\n",
        "        'min_latency': np.min(latencies),\n",
        "        'std_latency': np.std(latencies)\n",
        "    }\n",
        "\n",
        "    return stats"
      ],
      "metadata": {
        "id": "8kX_oBBI4sYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('open_ai_api_key')\n",
        "\n",
        "def get_chatgpt_answer(message: str, model, params={}) -> str:\n",
        "    chat_completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": message}],\n",
        "        **params\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "\n",
        "from anthropic import Anthropic\n",
        "\n",
        "client = Anthropic(\n",
        "    api_key=userdata.get(\"anthropic_key\")\n",
        ")\n",
        "\n",
        "def get_anthropic_answer(message: str, model, params={'max_tokens': 1024}) -> str:\n",
        "    answer = client.messages.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": message,\n",
        "            }\n",
        "        ],\n",
        "        model=model,\n",
        "        **params\n",
        "    )\n",
        "    return answer.content[0].text"
      ],
      "metadata": {
        "id": "vZ0xmTf25TF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_to_test = [\n",
        "   \"gpt-3.5-turbo\",\n",
        "   \"gpt-4\",\n",
        "   \"gpt-4o\",\n",
        "   'gpt-4o-mini',\n",
        "   \"claude-3-opus-20240229\",\n",
        "   \"claude-3-sonnet-20240229\",\n",
        "   \"claude-3-haiku-20240307\",\n",
        "   \"claude-3-5-sonnet-20240620\"\n",
        "]\n",
        "\n",
        "for model in models_to_test:\n",
        "    print(\"-\"*100)\n",
        "    print(f\"Model name {model}\")\n",
        "    if \"gpt\" in model:\n",
        "        completion_function = get_chatgpt_answer\n",
        "    else:\n",
        "        completion_function = get_anthropic_answer\n",
        "\n",
        "    print(measure_execution_time(\n",
        "        completion_function,\n",
        "        5,\n",
        "        \"What is the name of the cat from Shrek?\",\n",
        "        model,\n",
        "    ))\n",
        "\n",
        "    print(\"-\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P093gQgP6UCR",
        "outputId": "20ecb3cc-5587-41b3-a14c-355cce5ddfad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Model name gpt-3.5-turbo\n",
            "{'average_latency': 0.8572634220123291, 'max_latency': 1.2018272876739502, 'min_latency': 0.5498929023742676, 'std_latency': 0.21132660559943792}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name gpt-4\n",
            "{'average_latency': 1.3319780826568604, 'max_latency': 1.8591728210449219, 'min_latency': 1.0715179443359375, 'std_latency': 0.2895837058446255}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name gpt-4o\n",
            "{'average_latency': 1.4340587615966798, 'max_latency': 1.799485445022583, 'min_latency': 1.1727039813995361, 'std_latency': 0.20461863474660597}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name gpt-4o-mini\n",
            "{'average_latency': 0.8255136489868165, 'max_latency': 1.3149795532226562, 'min_latency': 0.52872633934021, 'std_latency': 0.2659238645855903}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name claude-3-opus-20240229\n",
            "{'average_latency': 6.670621252059936, 'max_latency': 7.630044460296631, 'min_latency': 4.185518026351929, 'std_latency': 1.2608159230239104}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name claude-3-sonnet-20240229\n",
            "{'average_latency': 4.2181846618652346, 'max_latency': 5.192933797836304, 'min_latency': 2.964183807373047, 'std_latency': 0.7858535191549963}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name claude-3-haiku-20240307\n",
            "{'average_latency': 1.3267467021942139, 'max_latency': 1.4615576267242432, 'min_latency': 1.0347704887390137, 'std_latency': 0.1652123840320664}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name claude-3-5-sonnet-20240620\n",
            "{'average_latency': 3.3828349113464355, 'max_latency': 4.40121865272522, 'min_latency': 2.0159788131713867, 'std_latency': 0.8275362826567593}\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are also parameters you can change to make latency a bit better. For example, if you want only a short sentence to be generated, you can set max_tokens. This speeds up response time a lot."
      ],
      "metadata": {
        "id": "zG0rGw187rno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model in models_to_test:\n",
        "    print(\"-\"*100)\n",
        "    print(f\"Model name {model}\")\n",
        "    if \"gpt\" in model:\n",
        "        completion_function = get_chatgpt_answer\n",
        "    else:\n",
        "        completion_function = get_anthropic_answer\n",
        "\n",
        "    print(measure_execution_time(\n",
        "        completion_function,\n",
        "        5,\n",
        "        \"What is the name of the cat from Shrek?\",\n",
        "        model,\n",
        "        params={\n",
        "            \"max_tokens\": 10\n",
        "        }\n",
        "    ))\n",
        "\n",
        "    print(\"-\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn7lZM8g7rLT",
        "outputId": "2b0e95ba-7960-4b28-ca19-c8d3f53b00a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Model name gpt-3.5-turbo\n",
            "{'average_latency': 0.5668250560760498, 'max_latency': 0.8016211986541748, 'min_latency': 0.4170095920562744, 'std_latency': 0.13576578001880066}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name gpt-4\n",
            "{'average_latency': 1.2162207126617433, 'max_latency': 1.757826328277588, 'min_latency': 0.9130477905273438, 'std_latency': 0.3195366842789354}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name gpt-4o\n",
            "{'average_latency': 0.735747241973877, 'max_latency': 0.9551527500152588, 'min_latency': 0.4709610939025879, 'std_latency': 0.1668785130025617}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name gpt-4o-mini\n",
            "{'average_latency': 0.5356669425964355, 'max_latency': 0.6896207332611084, 'min_latency': 0.4326934814453125, 'std_latency': 0.10505698717267943}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name claude-3-opus-20240229\n",
            "{'average_latency': 0.9264416217803955, 'max_latency': 0.9755957126617432, 'min_latency': 0.8509597778320312, 'std_latency': 0.05334933039670928}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name claude-3-sonnet-20240229\n",
            "{'average_latency': 0.5098380088806153, 'max_latency': 0.5639405250549316, 'min_latency': 0.47768139839172363, 'std_latency': 0.033344852107309725}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name claude-3-haiku-20240307\n",
            "{'average_latency': 0.4076198101043701, 'max_latency': 0.4381375312805176, 'min_latency': 0.3753323554992676, 'std_latency': 0.020479323556524355}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Model name claude-3-5-sonnet-20240620\n",
            "{'average_latency': 0.4694643497467041, 'max_latency': 0.5548872947692871, 'min_latency': 0.40474534034729004, 'std_latency': 0.051646240099701306}\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many other factors, which contribute to latency changes. For example lot of other people may be using the same model as you.\n",
        "\n",
        "In that case `gpt-4o-mini` can be slower than `gpt-4` just because of popularity at a certain time.  \n",
        "\n"
      ],
      "metadata": {
        "id": "bb2xRvSf78JK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "This week we've learned:\n",
        "- How to use LangChain library.\n",
        "- How to add plugins to an help an LLM excel in more complex tasks.\n",
        "- How to create a vector database and how to interact with it.\n",
        "- About LLM latency and what affects it\n",
        "\n",
        "\n",
        "In this week's homework you'll:\n",
        "- Learn how to make ChatGPT nail high-school tests.\n",
        "- Learn to route between different LLMs depending on the task.\n",
        "- Create you own Gradio app to demo your LLM functionality."
      ],
      "metadata": {
        "id": "w-O2uAyrrTUd"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}